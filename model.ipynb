{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Behavioral Cloning with Keras\n",
    "\n",
    "Using Keras to make building deep neural networks for predicting autonomous steering angles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dataset\n",
    "\n",
    "I am using the Udacity provided dataset as well as my personally collected simulator data around turns/corners that my model had a problem with. I initially tried collecting my own entire training set for the complete drive, but it seemed too jittery and not as smooth as I'd have liked, especially for steering recovery data.\n",
    "\n",
    "Here is the link from where I downloaded the data: https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip\n",
    "\n",
    "I am using Pandas to read the csv files and convert the first 3 columns to a numpy array to be used as feature vectors for the model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8036, 3)\n",
      "Training data downloaded and extracted into input arrays.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read data into data frames for further manipulation\n",
    "df = pd.read_csv('data/driving_log.csv')\n",
    "\n",
    "# Read all the ~8K samples from driving_log.csv, as training set.\n",
    "df_train_n_samples = df.iloc[:, :]\n",
    "# Extract another data frame to contain the input training images alone\n",
    "df_train_n_images = df_train_n_samples.loc[:,\"center\":\"right\"]\n",
    "\n",
    "print(df_train_n_images.values.shape)\n",
    "print('Training data downloaded and extracted into input arrays.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Read extra training data at special turns/corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 3)\n",
      "Extra training data around the corners downloaded and extracted into input arrays.\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('data/driving_log_additional.csv')\n",
    "\n",
    "# Read all the samples from driving_log_additional.csv, as extra training set around the corners.\n",
    "df_train_n_samples_2 = df2.iloc[:, :]\n",
    "# Extract another data frame to contain the input training images alone\n",
    "df_train_n_images_2 = df_train_n_samples_2.loc[:,\"center\":\"right\"]\n",
    "\n",
    "print(df_train_n_images_2.values.shape)\n",
    "print('Extra training data around the corners downloaded and extracted into input arrays.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Overview\n",
    "\n",
    "Here are the steps I'm taking build the network:\n",
    "\n",
    "1. Load the image training data from the pandas dataframe.\n",
    "2. Preprocess the data.\n",
    "3. Build a convolutional neural network to predict steering angles.\n",
    "4. Save the training model and weights \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load the Data\n",
    "\n",
    "Start by using the input pandas data frame to read images from the data/IMG folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataframe shape =  (8036, 3)\n",
      "X_train.shape =  (24108, 66, 200, 3)\n",
      "X_train_turns.shape =  (447, 66, 200, 3)\n",
      "len(X_train) =  24108\n",
      "y_train.shape =  (24108,)\n",
      "len(y_train) =  24108\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load image from csv contents and resize to (66x200) to match  Nvidia pipeline architecture\n",
    "def LoadImageFromNameMatrix(ImageFileNamesDataFrame):\n",
    "    Image_Samples = []\n",
    "    filename = []\n",
    "    filename.append('data/')\n",
    "    for row in range(ImageFileNamesDataFrame.shape[0]):\n",
    "        for col in range(ImageFileNamesDataFrame.shape[1]):\n",
    "            # make a shallow copy to avoid mutating original list\n",
    "            temp = list(filename)\n",
    "            temp.append(ImageFileNamesDataFrame[row][col].replace(\" \", \"\"))\n",
    "            inputFile = ''.join(temp)\n",
    "            image = mpimg.imread(inputFile)\n",
    "            resized_image = cv2.resize(image,(200,66),interpolation = cv2.INTER_CUBIC)\n",
    "            Image_Samples.append(resized_image)\n",
    "    return Image_Samples\n",
    "\n",
    "# Load the feature data in the variables X_train and X_train_turns- (samples x features)\n",
    "X_train = LoadImageFromNameMatrix(df_train_n_images.values)\n",
    "X_train_turns = LoadImageFromNameMatrix(df_train_n_images_2.values)\n",
    "\n",
    "# Load the output label data in the variables y_train and y_train_turns\n",
    "y_train = df_train_n_samples.loc[:,\"steering\"].values\n",
    "y_train = np.repeat(y_train, df_train_n_images.values.shape[-1])\n",
    "y_train_turns = df_train_n_samples_2.loc[:,\"steering\"].values\n",
    "y_train_turns = np.repeat(y_train_turns, df_train_n_images_2.values.shape[-1])\n",
    "\n",
    "# Print sample set dimensions of input data read\n",
    "print ('Image dataframe shape = ', df_train_n_images.values.shape)\n",
    "print ('X_train.shape = ', np.array(X_train).shape)\n",
    "print ('X_train_turns.shape = ', np.array(X_train_turns).shape)\n",
    "print ('len(X_train) = ', len(X_train))\n",
    "print ('y_train.shape = ', np.array(y_train).shape)\n",
    "print ('len(y_train) = ', len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Augment data\n",
    "1. Dither the left and right steering angles associated with center images, by a small adjustment factor for recovery.\n",
    "2. Also, generate additional data by creating reflections of left and right camera images and angles.\n",
    "3. Augment the above ahead of the data in driving straight, to avoid bias. \n",
    "4. To further prevent overfitting and bias in driving straight, drop a few center images associated with 0 steering angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:17: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:38: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/__main__.py:39: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation and augmentation done\n"
     ]
    }
   ],
   "source": [
    "# Input pre-processing step - dither the left and right steering angles by a small amount for recovery\n",
    "STEERING_DITHER = 0.2\n",
    "\n",
    "## Additional training data at the turns - Left image's steering angle dither by 0.2\n",
    "y_train_turns[1::3] = [x + STEERING_DITHER for x in y_train_turns[1::3]]\n",
    "\n",
    "## Additional training data at the turns - Right image's steering angle dither by 0.2\n",
    "y_train_turns[2::3] = [x - STEERING_DITHER for x in y_train_turns[2::3]]\n",
    "\n",
    "## Augment the additional data set at the turns by generating reflections of left/right images\n",
    "new_X_count = (np.array(X_train_turns).shape[0] *2 )/3\n",
    "new_X_rows = np.array(X_train_turns).shape[1]\n",
    "new_X_columns = np.array(X_train_turns).shape[2]\n",
    "\n",
    "new_y_count = (np.array(y_train_turns).shape[0] *2 )/3\n",
    "\n",
    "X_train_turns_flipped = np.empty(shape=(new_X_count, new_X_rows, new_X_columns), dtype = np.float32).tolist()\n",
    "y_train_turns_flipped = np.empty(shape=(new_y_count), dtype = np.float32).tolist()\n",
    "\n",
    "X_train_turns_flipped[0::2] = [np.fliplr(x) for x in X_train_turns[1::3]]\n",
    "X_train_turns_flipped[1::2] = [np.fliplr(x) for x in X_train_turns[2::3]]\n",
    "y_train_turns_flipped[0::2] = [x* (-1) for x in y_train_turns[1::3]]\n",
    "y_train_turns_flipped[1::2] = [x* (-1) for x in y_train_turns[2::3]]\n",
    "\n",
    "## Original Udacity training data - Dither the right camera image steering angle by 0.2, for 0 steering angle inputs\n",
    "y_train[2::3] = [x - STEERING_DITHER * (x == 0) for x in y_train[2::3]]\n",
    "\n",
    "## Original Udacity training data - Dither the left camera image steering angle by 0.2, for 0 steering angle inputs\n",
    "y_train[1::3] = [x + STEERING_DITHER * (x == 0) for x in y_train[1::3]]\n",
    "\n",
    "## Augment the original Udacity data set by generating reflections\n",
    "new_X_flipped_count = (np.array(X_train).shape[0] *2 )/3\n",
    "new_X_flipped_rows = np.array(X_train).shape[1]\n",
    "new_X_flipped_columns = np.array(X_train).shape[2]\n",
    "\n",
    "new_y_flipped_count = (np.array(y_train).shape[0] *2 )/3\n",
    "\n",
    "X_train_flipped = np.empty(shape=(new_X_flipped_count, new_X_flipped_rows, new_X_flipped_columns), dtype = np.float32).tolist()\n",
    "y_train_flipped = np.empty(shape=(new_y_flipped_count), dtype = np.float32).tolist()\n",
    "\n",
    "X_train_flipped[0::2] = [np.fliplr(x) for x in X_train[1::3]]\n",
    "X_train_flipped[1::2] = [np.fliplr(x) for x in X_train[2::3]]\n",
    "y_train_flipped[0::2] = [x* (-1) for x in y_train[1::3]]\n",
    "y_train_flipped[1::2] = [x* (-1) for x in y_train[2::3]]\n",
    "\n",
    "print ('Data generation and augmentation done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataframe shape =  (8036, 3)\n",
      "X_train.shape =  (36832, 66, 200, 3)\n",
      "len(X_train) =  36832\n",
      "y_train.shape =  (36832,)\n",
      "len(y_train) =  36832\n",
      "X_valid.shape =  (4093, 66, 200, 3)\n",
      "len(X_valid) =  4093\n",
      "y_valid.shape =  (4093,)\n",
      "len(y_valid) =  4093\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIEkdZQBIUkf9f3dZyOHXMlIJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff78e2bc0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Combine the two data sets - Udacity original + extra training data at the turns and it's reflections \n",
    "y_train = np.array(y_train_flipped + y_train_turns_flipped + y_train_turns.tolist() + y_train.tolist())\n",
    "\n",
    "X_train = X_train_flipped + X_train_turns_flipped + X_train_turns + X_train\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print sample set dimensions of input data read\n",
    "print ('Image dataframe shape = ', df_train_n_images.values.shape)\n",
    "print ('X_train.shape = ', X_train.shape)\n",
    "print ('len(X_train) = ', len(X_train))\n",
    "print ('y_train.shape = ', y_train.shape)\n",
    "print ('len(y_train) = ', len(y_train))\n",
    "print ('X_valid.shape = ', X_valid.shape)\n",
    "print ('len(X_valid) = ', len(X_valid))\n",
    "print ('y_valid.shape = ', y_valid.shape)\n",
    "print ('len(y_valid) = ', len(y_valid))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "hist, bins = np.histogram(y_train, bins='auto',range=(-0.5,0.5))\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess the Data\n",
    "\n",
    "Perform the following pre-processing via a generator\n",
    "  1. Normalize the features using Min-Max scaling between -0.5 and 0.5\n",
    "  2. Perform brightness adjustment before normalizing data.\n",
    "  3. Flip the inputs along the vertical axis and update angle accordingly to generate balanced data.\n",
    "  4. Remove bias towards 0 values by dropping data below a random threshold after adding a static bias offset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Normalize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Normalize the data features using Min-Max scaling\n",
    "def normalize_min_max(image):\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    return a + (((image - image_min) * (b - a))/ (image_max - image_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Add brightness adjustment, flip along y-axis and remove bias towards 0 angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data generated and normalized\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "STATIC_BIAS = 0.1\n",
    "TRANSLATION_X_RANGE = 99\n",
    "TRANSLATION_Y_RANGE = 0.3\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "\n",
    "# Generate random brightness function, produce darker transformation \n",
    "def brightness(image):\n",
    "    #Convert 2 HSV colorspace from RGB colorspace\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    #Generate new random brightness\n",
    "    rand = random.uniform(0.5,1.0)\n",
    "    hsv[:,:,2] = rand * hsv[:,:,2]\n",
    "    #Convert back to RGB colorspace\n",
    "    new_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return new_image\n",
    "\n",
    "# Horizontal translation to left/right to generate more data for non-trivial steering predictions\n",
    "def horizontal_translation(image, pixels):\n",
    "    (rows,cols, channels) = image.shape\n",
    "    M = np.float32([[1,0,pixels],[0,1,0]])\n",
    "    dst = cv2.warpAffine(image,M,(cols,rows))\n",
    "    return dst\n",
    "\n",
    "# Data generator to produce data based on random choice, thus inherently shuffling the data.\n",
    "def myTrainGenerator(batch_size):\n",
    "    k = 0\n",
    "    while 1:\n",
    "        print (\"\\n\")\n",
    "        k = k + 1\n",
    "        print ('iteration= ', k)\n",
    "        i = 0\n",
    "        # Initialize batches of input data\n",
    "        batch_X = np.zeros((batch_size, 66, 200, 3), dtype = np.float32)\n",
    "        batch_y = np.zeros((batch_size,), dtype = np.float32)\n",
    "        while (i < batch_size):\n",
    "            choice = np.random.choice(len(X_train))\n",
    "            batch_X[i] = brightness(X_train[choice])            \n",
    "            batch_X[i] = normalize_min_max(batch_X[i])\n",
    "            batch_y[i] = y_train[choice]\n",
    "\n",
    "            # Remove bias towards small angles with a bias term and threshold, by reselecting\n",
    "            threshold = np.random.uniform(0.1,0.2)\n",
    "            if ((abs(batch_y[i]) + STATIC_BIAS) < threshold):\n",
    "                choice = np.random.choice(len(X_train))\n",
    "                batch_X[i] = brightness(X_train[choice])            \n",
    "                batch_X[i] = normalize_min_max(batch_X[i])\n",
    "                batch_y[i] = y_train[choice]\n",
    "            # Apply horizontal translation to low steering angles (< 0.1) to 70% of qualified images\n",
    "            translate_prob = np.random.uniform(0,1)\n",
    "            if (abs(batch_y[i]) < 0.1 and translate_prob >= 0.3):\n",
    "                angle = np.random.uniform(0,1)\n",
    "                pixels = int((TRANSLATION_X_RANGE * angle)/TRANSLATION_Y_RANGE)\n",
    "                if (batch_y[i] > 0):\n",
    "                    # If steering angle is tending to the right, translate image to the right\n",
    "                    # and decrease right steering to recover and be on the track\n",
    "                    batch_X[i] = horizontal_translation(batch_X[i], pixels)\n",
    "                    batch_y[i] = batch_y[i] - angle\n",
    "                else:\n",
    "                    # If steering angle is tending to the left, translate image to the left\n",
    "                    # and decrease left steering to recover and be on the track\n",
    "                    batch_X[i] = horizontal_translation(batch_X[i], -pixels)\n",
    "                    batch_y[i] = batch_y[i] + angle\n",
    "            i = i + 1\n",
    "        yield (batch_X, batch_y)\n",
    "\n",
    "\n",
    "def myValidationGenerator(X_validation, y_validation, batch_size):\n",
    "    while 1:\n",
    "        X_val, y_val = shuffle(X_validation, y_validation)\n",
    "        batch_X = np.zeros((batch_size, 66, 200, 3), dtype = np.float32)\n",
    "        batch_y = np.zeros((batch_size,), dtype = np.float32)\n",
    "        i = 0         \n",
    "        for i in range(batch_size):\n",
    "            choice = np.random.choice(len(X_val))\n",
    "            batch_X[i] = X_val[choice]\n",
    "            batch_X[i] = brightness(X_val[choice])  \n",
    "            batch_X[i] = normalize_min_max(batch_X[i])\n",
    "            batch_y[i] = y_val[choice]\n",
    "        yield (batch_X, batch_y)\n",
    "\n",
    "print('Validation data generated and normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Keras Layers\n",
    "We'll be using the layers of Keras to build our network, such as convolution, activation, fully connected, etc.  A layer can be added to the model using the model's `add()` function.  Here is a network based on NVIDIA's paper\n",
    "https://arxiv.org/pdf/1604.07316v1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build a Multi-Layer Network following NVIDIA architecture\n",
    "\n",
    "Build a multi-layer feedforward neural network to predict steering angles, using the NVIDIA architecture.\n",
    "\n",
    "1. Set the first layer to a `Convolution2D` layer with 5x5 kernel, `input_shape` set to (66, 200, 3) and `subsample` to (1,1)\n",
    "2. Use a `MaxPooling2D` layer that subsamples by (2,2) after the previous convolution.\n",
    "3. Use a `Dropout` layer at 0.5 dropout, following the pooling layer.\n",
    "4. Use a `ReLU` activation function after the Dropout layer.\n",
    "5. Set the fifth layer to a `Convolution2D` layer with 5x5 kernel, `valid` padding and `subsample` set to (2,1). The input shape from the previous operations result in (w,h)=(31,98)\n",
    "6. Use a `MaxPooling2D` layer that `subsamples` by (1,2) after the previous convolution in the fifth layer.\n",
    "7. Use a `Dropout` layer at 0.5 dropout, following the pooling layer.\n",
    "8. Use a `ReLU` activation function after the Dropout layer.\n",
    "9. Set the ninth layer to a `Convolution2D` layer with 5x5 kernel, `valid` padding and `subsample` set to (1,2). The input shape from the previous operations result in (w,h)=(14,47)\n",
    "10. Use a `MaxPooling2D` layer that `subsamples` by (2,1) after the previous convolution.\n",
    "11. Use a `Dropout` layer at 0.5 dropout, following the pooling layer.\n",
    "12. Use a `ReLU` activation function after the Dropout layer.\n",
    "13. Set the thirteenth layer to a `Convolution2D` layer with 3x3 kernel, `valid` padding and `subsample` set to (1,1).  The input shape from the previous operations result in (w,h)=(5,22)\n",
    "14. Use a `ReLU` activation function after the convolution layer.\n",
    "15. Set the fifteenth layer to a `Convolution2D` layer with 3x3 kernel, `valid` padding and `subsample` set to (1,1).  The input shape from the previous operations result in (w,h)=(3,20)\n",
    "16. Use a `ReLU` activation function after the previous convolution.\n",
    "17. Set the seventeenth layer to a `Flatten` layer with the `input_shape` set to (1, 18, 64), which flattens it to output 1152 neurons.\n",
    "18. Feed the flattened output to a `Dense` layer width to 100 output neurons.\n",
    "19. Use a `ReLU` activation function after the Dense layer output.\n",
    "20. Set the twentieth layer to `Dense` layer width to 50 output neurons. \n",
    "21. Use a `ReLU` activation function after the above Dense layer.\n",
    "22. Set the twenty-second layer to `Dense` layer width to 10 output neurons. \n",
    "23. Use a `ReLU` activation function after the previous Dense layer.\n",
    "24. Set the final layer to `Dense` layer width to 1 output neuron.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Network with Dropout\n",
    "1. Construct the network with Dropout, as the network tends to be overfit with large amounts of training and augmented data.\n",
    "2. Add a dropout layers after the pooling layers. Set the dropout rate to 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network created\n"
     ]
    }
   ],
   "source": [
    "# Construct the network and add dropout after the pooling layer.\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(24, 5, 5, border_mode='valid', subsample=(1,1), input_shape=(66, 200, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Input size (w,h)=(31,98)\n",
    "model.add(Convolution2D(36, 5, 5, border_mode='valid', subsample=(2,1)))\n",
    "model.add(MaxPooling2D((1, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Input size (w,h)=(14,47)\n",
    "model.add(Convolution2D(48, 5, 5, border_mode='valid', subsample=(1,2)))\n",
    "model.add(MaxPooling2D((2, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Input size (w,h)=(5,22)\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid', subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Input size (w,h)=(3,20)\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid', subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Flatten the input to 64*1*18 = 1152 neurons\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "print ('Network created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Network\n",
    "\n",
    "1. Compile the network using adam optimizer and MSE loss function.\n",
    "2. Train the network for 7 epochs to avoid underfitting and to get better loss as the training data is augmented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_11 (Convolution2D) (None, 62, 196, 24)   1824        convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 31, 98, 24)    0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 31, 98, 24)    0           maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 31, 98, 24)    0           dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 14, 94, 36)    21636       activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 14, 47, 36)    0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 14, 47, 36)    0           maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 14, 47, 36)    0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 10, 22, 48)    43248       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 5, 22, 48)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 5, 22, 48)     0           maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 5, 22, 48)     0           dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 3, 20, 64)     27712       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 3, 20, 64)     0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 1, 18, 64)     36928       activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 1, 18, 64)     0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 1152)          0           activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 100)           115300      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 100)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 50)            5050        activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 50)            0           dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 10)            510         activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 10)            0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 1)             11          activation_24[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "iteration=  1\n",
      "Epoch 1/7\n",
      "\n",
      "\n",
      "iteration=  2\n",
      "\n",
      "\n",
      "iteration=  3\n",
      "\n",
      "\n",
      "iteration=  4\n",
      "\n",
      "\n",
      "iteration=  5\n",
      "  256/36832 [..............................] - ETA: 207s - loss: 0.0698\n",
      "\n",
      "iteration=  6\n",
      "\n",
      "\n",
      "iteration=  7\n",
      "\n",
      "\n",
      "iteration=  8\n",
      "  512/36832 [..............................] - ETA: 134s - loss: 0.0713\n",
      "\n",
      "iteration=  9\n",
      "\n",
      "\n",
      "iteration=  10\n",
      "  768/36832 [..............................] - ETA: 109s - loss: 0.0741\n",
      "\n",
      "iteration=  11\n",
      "\n",
      "\n",
      "iteration=  12\n",
      "\n",
      "\n",
      "iteration=  13\n",
      " 1024/36832 [..............................] - ETA: 97s - loss: 0.0729 \n",
      "\n",
      "iteration=  14\n",
      "\n",
      "\n",
      "iteration=  15\n",
      " 1280/36832 [>.............................] - ETA: 89s - loss: 0.0718\n",
      "\n",
      "iteration=  16\n",
      " 1536/36832 [>.............................] - ETA: 84s - loss: 0.0701\n",
      "\n",
      "iteration=  17\n",
      " 1792/36832 [>.............................] - ETA: 80s - loss: 0.0717\n",
      "\n",
      "iteration=  18\n",
      " 2048/36832 [>.............................] - ETA: 77s - loss: 0.0721\n",
      "\n",
      "iteration=  19\n",
      " 2304/36832 [>.............................] - ETA: 75s - loss: 0.0733\n",
      "\n",
      "iteration=  20\n",
      " 2560/36832 [=>............................] - ETA: 73s - loss: 0.0735\n",
      "\n",
      "iteration=  21\n",
      " 2816/36832 [=>............................] - ETA: 71s - loss: 0.0740\n",
      "\n",
      "iteration=  22\n",
      " 3072/36832 [=>............................] - ETA: 69s - loss: 0.0731\n",
      "\n",
      "iteration=  23\n",
      " 3328/36832 [=>............................] - ETA: 68s - loss: 0.0724\n",
      "\n",
      "iteration=  24\n",
      " 3584/36832 [=>............................] - ETA: 67s - loss: 0.0728\n",
      "\n",
      "iteration=  25\n",
      " 3840/36832 [==>...........................] - ETA: 65s - loss: 0.0722\n",
      "\n",
      "iteration=  26\n",
      " 4096/36832 [==>...........................] - ETA: 64s - loss: 0.0720\n",
      "\n",
      "iteration=  27\n",
      " 4352/36832 [==>...........................] - ETA: 63s - loss: 0.0722\n",
      "\n",
      "iteration=  28\n",
      " 4608/36832 [==>...........................] - ETA: 63s - loss: 0.0717\n",
      "\n",
      "iteration=  29\n",
      " 4864/36832 [==>...........................] - ETA: 62s - loss: 0.0709\n",
      "\n",
      "iteration=  30\n",
      " 5120/36832 [===>..........................] - ETA: 61s - loss: 0.0710\n",
      "\n",
      "iteration=  31\n",
      " 5376/36832 [===>..........................] - ETA: 60s - loss: 0.0707\n",
      "\n",
      "iteration=  32\n",
      " 5632/36832 [===>..........................] - ETA: 59s - loss: 0.0705\n",
      "\n",
      "iteration=  33\n",
      " 5888/36832 [===>..........................] - ETA: 59s - loss: 0.0705\n",
      "\n",
      "iteration=  34\n",
      " 6144/36832 [====>.........................] - ETA: 58s - loss: 0.0704\n",
      "\n",
      "iteration=  35\n",
      " 6400/36832 [====>.........................] - ETA: 57s - loss: 0.0706\n",
      "\n",
      "iteration=  36\n",
      " 6656/36832 [====>.........................] - ETA: 57s - loss: 0.0701\n",
      "\n",
      "iteration=  37\n",
      " 6912/36832 [====>.........................] - ETA: 56s - loss: 0.0698\n",
      "\n",
      "iteration=  38\n",
      " 7168/36832 [====>.........................] - ETA: 55s - loss: 0.0692\n",
      "\n",
      "iteration=  39\n",
      " 7424/36832 [=====>........................] - ETA: 55s - loss: 0.0693\n",
      "\n",
      "iteration=  40\n",
      " 7680/36832 [=====>........................] - ETA: 54s - loss: 0.0687\n",
      "\n",
      "iteration=  41\n",
      " 7936/36832 [=====>........................] - ETA: 53s - loss: 0.0685\n",
      "\n",
      "iteration=  42\n",
      " 8192/36832 [=====>........................] - ETA: 53s - loss: 0.0684\n",
      "\n",
      "iteration=  43\n",
      " 8448/36832 [=====>........................] - ETA: 52s - loss: 0.0683\n",
      "\n",
      "iteration=  44\n",
      " 8704/36832 [======>.......................] - ETA: 52s - loss: 0.0684\n",
      "\n",
      "iteration=  45\n",
      " 8960/36832 [======>.......................] - ETA: 51s - loss: 0.0681\n",
      "\n",
      "iteration=  46\n",
      " 9216/36832 [======>.......................] - ETA: 51s - loss: 0.0677\n",
      "\n",
      "iteration=  47\n",
      " 9472/36832 [======>.......................] - ETA: 50s - loss: 0.0670\n",
      "\n",
      "iteration=  48\n",
      " 9728/36832 [======>.......................] - ETA: 49s - loss: 0.0672\n",
      "\n",
      "iteration=  49\n",
      " 9984/36832 [=======>......................] - ETA: 49s - loss: 0.0671\n",
      "\n",
      "iteration=  50\n",
      "10240/36832 [=======>......................] - ETA: 48s - loss: 0.0671\n",
      "\n",
      "iteration=  51\n",
      "10496/36832 [=======>......................] - ETA: 48s - loss: 0.0668\n",
      "\n",
      "iteration=  52\n",
      "10752/36832 [=======>......................] - ETA: 47s - loss: 0.0664\n",
      "\n",
      "iteration=  53\n",
      "11008/36832 [=======>......................] - ETA: 47s - loss: 0.0659\n",
      "\n",
      "iteration=  54\n",
      "11264/36832 [========>.....................] - ETA: 46s - loss: 0.0655\n",
      "\n",
      "iteration=  55\n",
      "11520/36832 [========>.....................] - ETA: 46s - loss: 0.0652\n",
      "\n",
      "iteration=  56\n",
      "11776/36832 [========>.....................] - ETA: 45s - loss: 0.0650\n",
      "\n",
      "iteration=  57\n",
      "12032/36832 [========>.....................] - ETA: 45s - loss: 0.0647\n",
      "\n",
      "iteration=  58\n",
      "12288/36832 [=========>....................] - ETA: 44s - loss: 0.0646\n",
      "\n",
      "iteration=  59\n",
      "12544/36832 [=========>....................] - ETA: 44s - loss: 0.0647\n",
      "\n",
      "iteration=  60\n",
      "12800/36832 [=========>....................] - ETA: 43s - loss: 0.0644\n",
      "\n",
      "iteration=  61\n",
      "13056/36832 [=========>....................] - ETA: 43s - loss: 0.0641\n",
      "\n",
      "iteration=  62\n",
      "13312/36832 [=========>....................] - ETA: 42s - loss: 0.0639\n",
      "\n",
      "iteration=  63\n",
      "13568/36832 [==========>...................] - ETA: 42s - loss: 0.0637\n",
      "\n",
      "iteration=  64\n",
      "13824/36832 [==========>...................] - ETA: 41s - loss: 0.0635\n",
      "\n",
      "iteration=  65\n",
      "14080/36832 [==========>...................] - ETA: 41s - loss: 0.0633\n",
      "\n",
      "iteration=  66\n",
      "14336/36832 [==========>...................] - ETA: 40s - loss: 0.0630\n",
      "\n",
      "iteration=  67\n",
      "14592/36832 [==========>...................] - ETA: 40s - loss: 0.0628\n",
      "\n",
      "iteration=  68\n",
      "14848/36832 [===========>..................] - ETA: 39s - loss: 0.0626\n",
      "\n",
      "iteration=  69\n",
      "15104/36832 [===========>..................] - ETA: 39s - loss: 0.0623\n",
      "\n",
      "iteration=  70\n",
      "15360/36832 [===========>..................] - ETA: 38s - loss: 0.0620\n",
      "\n",
      "iteration=  71\n",
      "15616/36832 [===========>..................] - ETA: 38s - loss: 0.0617\n",
      "\n",
      "iteration=  72\n",
      "15872/36832 [===========>..................] - ETA: 37s - loss: 0.0614\n",
      "\n",
      "iteration=  73\n",
      "16128/36832 [============>.................] - ETA: 37s - loss: 0.0612\n",
      "\n",
      "iteration=  74\n",
      "16384/36832 [============>.................] - ETA: 36s - loss: 0.0611\n",
      "\n",
      "iteration=  75\n",
      "16640/36832 [============>.................] - ETA: 36s - loss: 0.0612\n",
      "\n",
      "iteration=  76\n",
      "16896/36832 [============>.................] - ETA: 35s - loss: 0.0610\n",
      "\n",
      "iteration=  77\n",
      "17152/36832 [============>.................] - ETA: 35s - loss: 0.0606\n",
      "\n",
      "iteration=  78\n",
      "17408/36832 [=============>................] - ETA: 34s - loss: 0.0606\n",
      "\n",
      "iteration=  79\n",
      "17664/36832 [=============>................] - ETA: 34s - loss: 0.0604\n",
      "\n",
      "iteration=  80\n",
      "17920/36832 [=============>................] - ETA: 33s - loss: 0.0604\n",
      "\n",
      "iteration=  81\n",
      "18176/36832 [=============>................] - ETA: 33s - loss: 0.0604\n",
      "\n",
      "iteration=  82\n",
      "18432/36832 [==============>...............] - ETA: 32s - loss: 0.0603\n",
      "\n",
      "iteration=  83\n",
      "18688/36832 [==============>...............] - ETA: 32s - loss: 0.0600\n",
      "\n",
      "iteration=  84\n",
      "18944/36832 [==============>...............] - ETA: 32s - loss: 0.0597\n",
      "\n",
      "iteration=  85\n",
      "19200/36832 [==============>...............] - ETA: 31s - loss: 0.0596\n",
      "\n",
      "iteration=  86\n",
      "19456/36832 [==============>...............] - ETA: 31s - loss: 0.0595\n",
      "\n",
      "iteration=  87\n",
      "19712/36832 [===============>..............] - ETA: 30s - loss: 0.0595\n",
      "\n",
      "iteration=  88\n",
      "19968/36832 [===============>..............] - ETA: 30s - loss: 0.0594\n",
      "\n",
      "iteration=  89\n",
      "20224/36832 [===============>..............] - ETA: 29s - loss: 0.0592\n",
      "\n",
      "iteration=  90\n",
      "20480/36832 [===============>..............] - ETA: 29s - loss: 0.0590\n",
      "\n",
      "iteration=  91\n",
      "20736/36832 [===============>..............] - ETA: 28s - loss: 0.0589\n",
      "\n",
      "iteration=  92\n",
      "20992/36832 [================>.............] - ETA: 28s - loss: 0.0588\n",
      "\n",
      "iteration=  93\n",
      "21248/36832 [================>.............] - ETA: 27s - loss: 0.0588\n",
      "\n",
      "iteration=  94\n",
      "21504/36832 [================>.............] - ETA: 27s - loss: 0.0587\n",
      "\n",
      "iteration=  95\n",
      "21760/36832 [================>.............] - ETA: 26s - loss: 0.0586\n",
      "\n",
      "iteration=  96\n",
      "22016/36832 [================>.............] - ETA: 26s - loss: 0.0585\n",
      "\n",
      "iteration=  97\n",
      "22272/36832 [=================>............] - ETA: 25s - loss: 0.0586\n",
      "\n",
      "iteration=  98\n",
      "22528/36832 [=================>............] - ETA: 25s - loss: 0.0584\n",
      "\n",
      "iteration=  99\n",
      "22784/36832 [=================>............] - ETA: 25s - loss: 0.0582\n",
      "\n",
      "iteration=  100\n",
      "23040/36832 [=================>............] - ETA: 24s - loss: 0.0580\n",
      "\n",
      "iteration=  101\n",
      "23296/36832 [=================>............] - ETA: 24s - loss: 0.0580\n",
      "\n",
      "iteration=  102\n",
      "23552/36832 [==================>...........] - ETA: 23s - loss: 0.0579\n",
      "\n",
      "iteration=  103\n",
      "23808/36832 [==================>...........] - ETA: 23s - loss: 0.0578\n",
      "\n",
      "iteration=  104\n",
      "24064/36832 [==================>...........] - ETA: 22s - loss: 0.0576\n",
      "\n",
      "iteration=  105\n",
      "24320/36832 [==================>...........] - ETA: 22s - loss: 0.0575\n",
      "\n",
      "iteration=  106\n",
      "24576/36832 [===================>..........] - ETA: 21s - loss: 0.0574\n",
      "\n",
      "iteration=  107\n",
      "24832/36832 [===================>..........] - ETA: 21s - loss: 0.0573\n",
      "\n",
      "iteration=  108\n",
      "25088/36832 [===================>..........] - ETA: 20s - loss: 0.0572\n",
      "\n",
      "iteration=  109\n",
      "25344/36832 [===================>..........] - ETA: 20s - loss: 0.0572\n",
      "\n",
      "iteration=  110\n",
      "25600/36832 [===================>..........] - ETA: 19s - loss: 0.0572\n",
      "\n",
      "iteration=  111\n",
      "25856/36832 [====================>.........] - ETA: 19s - loss: 0.0572\n",
      "\n",
      "iteration=  112\n",
      "26112/36832 [====================>.........] - ETA: 19s - loss: 0.0572\n",
      "\n",
      "iteration=  113\n",
      "26368/36832 [====================>.........] - ETA: 18s - loss: 0.0572\n",
      "\n",
      "iteration=  114\n",
      "26624/36832 [====================>.........] - ETA: 18s - loss: 0.0570\n",
      "\n",
      "iteration=  115\n",
      "26880/36832 [====================>.........] - ETA: 17s - loss: 0.0568\n",
      "\n",
      "iteration=  116\n",
      "27136/36832 [=====================>........] - ETA: 17s - loss: 0.0566\n",
      "\n",
      "iteration=  117\n",
      "27392/36832 [=====================>........] - ETA: 16s - loss: 0.0567\n",
      "\n",
      "iteration=  118\n",
      "27648/36832 [=====================>........] - ETA: 16s - loss: 0.0565\n",
      "\n",
      "iteration=  119\n",
      "27904/36832 [=====================>........] - ETA: 15s - loss: 0.0565\n",
      "\n",
      "iteration=  120\n",
      "28160/36832 [=====================>........] - ETA: 15s - loss: 0.0564\n",
      "\n",
      "iteration=  121\n",
      "28416/36832 [======================>.......] - ETA: 14s - loss: 0.0563\n",
      "\n",
      "iteration=  122\n",
      "28672/36832 [======================>.......] - ETA: 14s - loss: 0.0563\n",
      "\n",
      "iteration=  123\n",
      "28928/36832 [======================>.......] - ETA: 14s - loss: 0.0563\n",
      "\n",
      "iteration=  124\n",
      "29184/36832 [======================>.......] - ETA: 13s - loss: 0.0563\n",
      "\n",
      "iteration=  125\n",
      "29440/36832 [======================>.......] - ETA: 13s - loss: 0.0564\n",
      "\n",
      "iteration=  126\n",
      "29696/36832 [=======================>......] - ETA: 12s - loss: 0.0563\n",
      "\n",
      "iteration=  127\n",
      "29952/36832 [=======================>......] - ETA: 12s - loss: 0.0562\n",
      "\n",
      "iteration=  128\n",
      "30208/36832 [=======================>......] - ETA: 11s - loss: 0.0561\n",
      "\n",
      "iteration=  129\n",
      "30464/36832 [=======================>......] - ETA: 11s - loss: 0.0561\n",
      "\n",
      "iteration=  130\n",
      "30720/36832 [========================>.....] - ETA: 10s - loss: 0.0560\n",
      "\n",
      "iteration=  131\n",
      "30976/36832 [========================>.....] - ETA: 10s - loss: 0.0560\n",
      "\n",
      "iteration=  132\n",
      "31232/36832 [========================>.....] - ETA: 9s - loss: 0.0560 \n",
      "\n",
      "iteration=  133\n",
      "31488/36832 [========================>.....] - ETA: 9s - loss: 0.0559\n",
      "\n",
      "iteration=  134\n",
      "31744/36832 [========================>.....] - ETA: 9s - loss: 0.0558\n",
      "\n",
      "iteration=  135\n",
      "32000/36832 [=========================>....] - ETA: 8s - loss: 0.0557\n",
      "\n",
      "iteration=  136\n",
      "32256/36832 [=========================>....] - ETA: 8s - loss: 0.0556\n",
      "\n",
      "iteration=  137\n",
      "32512/36832 [=========================>....] - ETA: 7s - loss: 0.0556\n",
      "\n",
      "iteration=  138\n",
      "32768/36832 [=========================>....] - ETA: 7s - loss: 0.0555\n",
      "\n",
      "iteration=  139\n",
      "33024/36832 [=========================>....] - ETA: 6s - loss: 0.0554\n",
      "\n",
      "iteration=  140\n",
      "33280/36832 [==========================>...] - ETA: 6s - loss: 0.0554\n",
      "\n",
      "iteration=  141\n",
      "33536/36832 [==========================>...] - ETA: 5s - loss: 0.0553\n",
      "\n",
      "iteration=  142\n",
      "33792/36832 [==========================>...] - ETA: 5s - loss: 0.0552\n",
      "\n",
      "iteration=  143\n",
      "34048/36832 [==========================>...] - ETA: 4s - loss: 0.0552\n",
      "\n",
      "iteration=  144\n",
      "34304/36832 [==========================>...] - ETA: 4s - loss: 0.0551\n",
      "\n",
      "iteration=  145\n",
      "34560/36832 [===========================>..] - ETA: 4s - loss: 0.0550\n",
      "\n",
      "iteration=  146\n",
      "34816/36832 [===========================>..] - ETA: 3s - loss: 0.0550\n",
      "\n",
      "iteration=  147\n",
      "35072/36832 [===========================>..] - ETA: 3s - loss: 0.0550\n",
      "\n",
      "iteration=  148\n",
      "35328/36832 [===========================>..] - ETA: 2s - loss: 0.0549\n",
      "\n",
      "iteration=  149\n",
      "35584/36832 [===========================>..] - ETA: 2s - loss: 0.0550\n",
      "\n",
      "iteration=  150\n",
      "35840/36832 [============================>.] - ETA: 1s - loss: 0.0549\n",
      "\n",
      "iteration=  151\n",
      "36096/36832 [============================>.] - ETA: 1s - loss: 0.0548\n",
      "\n",
      "iteration=  152\n",
      "36352/36832 [============================>.] - ETA: 0s - loss: 0.0548\n",
      "\n",
      "iteration=  153\n",
      "36608/36832 [============================>.] - ETA: 0s - loss: 0.0549\n",
      "\n",
      "iteration=  154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36864/36832 [==============================] - 68s - loss: 0.0549 - val_loss: 0.0213\n",
      "Epoch 2/7\n",
      "\n",
      "\n",
      "iteration=  155\n",
      "  256/36832 [..............................] - ETA: 63s - loss: 0.0322\n",
      "\n",
      "iteration=  156\n",
      "  512/36832 [..............................] - ETA: 63s - loss: 0.0395\n",
      "\n",
      "iteration=  157\n",
      "  768/36832 [..............................] - ETA: 62s - loss: 0.0435\n",
      "\n",
      "iteration=  158\n",
      " 1024/36832 [..............................] - ETA: 62s - loss: 0.0435\n",
      "\n",
      "iteration=  159\n",
      " 1280/36832 [>.............................] - ETA: 61s - loss: 0.0426\n",
      "\n",
      "iteration=  160\n",
      " 1536/36832 [>.............................] - ETA: 61s - loss: 0.0432\n",
      "\n",
      "iteration=  161\n",
      " 1792/36832 [>.............................] - ETA: 60s - loss: 0.0422\n",
      "\n",
      "iteration=  162\n",
      " 2048/36832 [>.............................] - ETA: 60s - loss: 0.0429\n",
      "\n",
      "iteration=  163\n",
      " 2304/36832 [>.............................] - ETA: 59s - loss: 0.0439\n",
      "\n",
      "iteration=  164\n",
      " 2560/36832 [=>............................] - ETA: 59s - loss: 0.0455\n",
      "\n",
      "iteration=  165\n",
      " 2816/36832 [=>............................] - ETA: 59s - loss: 0.0456\n",
      "\n",
      "iteration=  166\n",
      " 3072/36832 [=>............................] - ETA: 58s - loss: 0.0446\n",
      "\n",
      "iteration=  167\n",
      " 3328/36832 [=>............................] - ETA: 58s - loss: 0.0444\n",
      "\n",
      "iteration=  168\n",
      " 3584/36832 [=>............................] - ETA: 57s - loss: 0.0437\n",
      "\n",
      "iteration=  169\n",
      " 3840/36832 [==>...........................] - ETA: 57s - loss: 0.0445\n",
      "\n",
      "iteration=  170\n",
      " 4096/36832 [==>...........................] - ETA: 56s - loss: 0.0444\n",
      "\n",
      "iteration=  171\n",
      " 4352/36832 [==>...........................] - ETA: 56s - loss: 0.0444\n",
      "\n",
      "iteration=  172\n",
      " 4608/36832 [==>...........................] - ETA: 56s - loss: 0.0447\n",
      "\n",
      "iteration=  173\n",
      " 4864/36832 [==>...........................] - ETA: 55s - loss: 0.0447\n",
      "\n",
      "iteration=  174\n",
      " 5120/36832 [===>..........................] - ETA: 55s - loss: 0.0450\n",
      "\n",
      "iteration=  175\n",
      " 5376/36832 [===>..........................] - ETA: 54s - loss: 0.0446\n",
      "\n",
      "iteration=  176\n",
      " 5632/36832 [===>..........................] - ETA: 54s - loss: 0.0443\n",
      "\n",
      "iteration=  177\n",
      " 5888/36832 [===>..........................] - ETA: 53s - loss: 0.0439\n",
      "\n",
      "iteration=  178\n",
      " 6144/36832 [====>.........................] - ETA: 53s - loss: 0.0444\n",
      "\n",
      "iteration=  179\n",
      " 6400/36832 [====>.........................] - ETA: 52s - loss: 0.0442\n",
      "\n",
      "iteration=  180\n",
      " 6656/36832 [====>.........................] - ETA: 52s - loss: 0.0442\n",
      "\n",
      "iteration=  181\n",
      " 6912/36832 [====>.........................] - ETA: 52s - loss: 0.0445\n",
      "\n",
      "iteration=  182\n",
      " 7168/36832 [====>.........................] - ETA: 51s - loss: 0.0448\n",
      "\n",
      "iteration=  183\n",
      " 7424/36832 [=====>........................] - ETA: 51s - loss: 0.0448\n",
      "\n",
      "iteration=  184\n",
      " 7680/36832 [=====>........................] - ETA: 50s - loss: 0.0445\n",
      "\n",
      "iteration=  185\n",
      " 7936/36832 [=====>........................] - ETA: 50s - loss: 0.0451\n",
      "\n",
      "iteration=  186\n",
      " 8192/36832 [=====>........................] - ETA: 49s - loss: 0.0449\n",
      "\n",
      "iteration=  187\n",
      " 8448/36832 [=====>........................] - ETA: 49s - loss: 0.0451\n",
      "\n",
      "iteration=  188\n",
      " 8704/36832 [======>.......................] - ETA: 48s - loss: 0.0453\n",
      "\n",
      "iteration=  189\n",
      " 8960/36832 [======>.......................] - ETA: 48s - loss: 0.0451\n",
      "\n",
      "iteration=  190\n",
      " 9216/36832 [======>.......................] - ETA: 48s - loss: 0.0450\n",
      "\n",
      "iteration=  191\n",
      " 9472/36832 [======>.......................] - ETA: 47s - loss: 0.0447\n",
      "\n",
      "iteration=  192\n",
      " 9728/36832 [======>.......................] - ETA: 47s - loss: 0.0452\n",
      "\n",
      "iteration=  193\n",
      " 9984/36832 [=======>......................] - ETA: 46s - loss: 0.0452\n",
      "\n",
      "iteration=  194\n",
      "10240/36832 [=======>......................] - ETA: 46s - loss: 0.0452\n",
      "\n",
      "iteration=  195\n",
      "10496/36832 [=======>......................] - ETA: 45s - loss: 0.0453\n",
      "\n",
      "iteration=  196\n",
      "10752/36832 [=======>......................] - ETA: 45s - loss: 0.0457\n",
      "\n",
      "iteration=  197\n",
      "11008/36832 [=======>......................] - ETA: 44s - loss: 0.0459\n",
      "\n",
      "iteration=  198\n",
      "11264/36832 [========>.....................] - ETA: 44s - loss: 0.0462\n",
      "\n",
      "iteration=  199\n",
      "11520/36832 [========>.....................] - ETA: 44s - loss: 0.0466\n",
      "\n",
      "iteration=  200\n",
      "11776/36832 [========>.....................] - ETA: 43s - loss: 0.0463\n",
      "\n",
      "iteration=  201\n",
      "12032/36832 [========>.....................] - ETA: 43s - loss: 0.0465\n",
      "\n",
      "iteration=  202\n",
      "12288/36832 [=========>....................] - ETA: 42s - loss: 0.0466\n",
      "\n",
      "iteration=  203\n",
      "12544/36832 [=========>....................] - ETA: 42s - loss: 0.0465\n",
      "\n",
      "iteration=  204\n",
      "12800/36832 [=========>....................] - ETA: 41s - loss: 0.0463\n",
      "\n",
      "iteration=  205\n",
      "13056/36832 [=========>....................] - ETA: 41s - loss: 0.0466\n",
      "\n",
      "iteration=  206\n",
      "13312/36832 [=========>....................] - ETA: 40s - loss: 0.0467\n",
      "\n",
      "iteration=  207\n",
      "13568/36832 [==========>...................] - ETA: 40s - loss: 0.0468\n",
      "\n",
      "iteration=  208\n",
      "13824/36832 [==========>...................] - ETA: 39s - loss: 0.0470\n",
      "\n",
      "iteration=  209\n",
      "14080/36832 [==========>...................] - ETA: 39s - loss: 0.0471\n",
      "\n",
      "iteration=  210\n",
      "14336/36832 [==========>...................] - ETA: 39s - loss: 0.0472\n",
      "\n",
      "iteration=  211\n",
      "14592/36832 [==========>...................] - ETA: 38s - loss: 0.0473\n",
      "\n",
      "iteration=  212\n",
      "14848/36832 [===========>..................] - ETA: 38s - loss: 0.0474\n",
      "\n",
      "iteration=  213\n",
      "15104/36832 [===========>..................] - ETA: 37s - loss: 0.0473\n",
      "\n",
      "iteration=  214\n",
      "15360/36832 [===========>..................] - ETA: 37s - loss: 0.0473\n",
      "\n",
      "iteration=  215\n",
      "15616/36832 [===========>..................] - ETA: 36s - loss: 0.0472\n",
      "\n",
      "iteration=  216\n",
      "15872/36832 [===========>..................] - ETA: 36s - loss: 0.0471\n",
      "\n",
      "iteration=  217\n",
      "16128/36832 [============>.................] - ETA: 35s - loss: 0.0467\n",
      "\n",
      "iteration=  218\n",
      "16384/36832 [============>.................] - ETA: 35s - loss: 0.0465\n",
      "\n",
      "iteration=  219\n",
      "16640/36832 [============>.................] - ETA: 35s - loss: 0.0465\n",
      "\n",
      "iteration=  220\n",
      "16896/36832 [============>.................] - ETA: 34s - loss: 0.0464\n",
      "\n",
      "iteration=  221\n",
      "17152/36832 [============>.................] - ETA: 34s - loss: 0.0463\n",
      "\n",
      "iteration=  222\n",
      "17408/36832 [=============>................] - ETA: 33s - loss: 0.0463\n",
      "\n",
      "iteration=  223\n",
      "17664/36832 [=============>................] - ETA: 33s - loss: 0.0465\n",
      "\n",
      "iteration=  224\n",
      "17920/36832 [=============>................] - ETA: 32s - loss: 0.0465\n",
      "\n",
      "iteration=  225\n",
      "18176/36832 [=============>................] - ETA: 32s - loss: 0.0465\n",
      "\n",
      "iteration=  226\n",
      "18432/36832 [==============>...............] - ETA: 31s - loss: 0.0466\n",
      "\n",
      "iteration=  227\n",
      "18688/36832 [==============>...............] - ETA: 31s - loss: 0.0466\n",
      "\n",
      "iteration=  228\n",
      "18944/36832 [==============>...............] - ETA: 31s - loss: 0.0465\n",
      "\n",
      "iteration=  229\n",
      "19200/36832 [==============>...............] - ETA: 30s - loss: 0.0465\n",
      "\n",
      "iteration=  230\n",
      "19456/36832 [==============>...............] - ETA: 30s - loss: 0.0464\n",
      "\n",
      "iteration=  231\n",
      "19712/36832 [===============>..............] - ETA: 29s - loss: 0.0464\n",
      "\n",
      "iteration=  232\n",
      "19968/36832 [===============>..............] - ETA: 29s - loss: 0.0464\n",
      "\n",
      "iteration=  233\n",
      "20224/36832 [===============>..............] - ETA: 28s - loss: 0.0467\n",
      "\n",
      "iteration=  234\n",
      "20480/36832 [===============>..............] - ETA: 28s - loss: 0.0466\n",
      "\n",
      "iteration=  235\n",
      "20736/36832 [===============>..............] - ETA: 27s - loss: 0.0465\n",
      "\n",
      "iteration=  236\n",
      "20992/36832 [================>.............] - ETA: 27s - loss: 0.0465\n",
      "\n",
      "iteration=  237\n",
      "21248/36832 [================>.............] - ETA: 27s - loss: 0.0465\n",
      "\n",
      "iteration=  238\n",
      "21504/36832 [================>.............] - ETA: 26s - loss: 0.0464\n",
      "\n",
      "iteration=  239\n",
      "21760/36832 [================>.............] - ETA: 26s - loss: 0.0464\n",
      "\n",
      "iteration=  240\n",
      "22016/36832 [================>.............] - ETA: 25s - loss: 0.0464\n",
      "\n",
      "iteration=  241\n",
      "22272/36832 [=================>............] - ETA: 25s - loss: 0.0464\n",
      "\n",
      "iteration=  242\n",
      "22528/36832 [=================>............] - ETA: 24s - loss: 0.0463\n",
      "\n",
      "iteration=  243\n",
      "22784/36832 [=================>............] - ETA: 24s - loss: 0.0463\n",
      "\n",
      "iteration=  244\n",
      "23040/36832 [=================>............] - ETA: 23s - loss: 0.0463\n",
      "\n",
      "iteration=  245\n",
      "23296/36832 [=================>............] - ETA: 23s - loss: 0.0463\n",
      "\n",
      "iteration=  246\n",
      "23552/36832 [==================>...........] - ETA: 23s - loss: 0.0463\n",
      "\n",
      "iteration=  247\n",
      "23808/36832 [==================>...........] - ETA: 22s - loss: 0.0463\n",
      "\n",
      "iteration=  248\n",
      "24064/36832 [==================>...........] - ETA: 22s - loss: 0.0462\n",
      "\n",
      "iteration=  249\n",
      "24320/36832 [==================>...........] - ETA: 21s - loss: 0.0463\n",
      "\n",
      "iteration=  250\n",
      "24576/36832 [===================>..........] - ETA: 21s - loss: 0.0462\n",
      "\n",
      "iteration=  251\n",
      "24832/36832 [===================>..........] - ETA: 20s - loss: 0.0461\n",
      "\n",
      "iteration=  252\n",
      "25088/36832 [===================>..........] - ETA: 20s - loss: 0.0461\n",
      "\n",
      "iteration=  253\n",
      "25344/36832 [===================>..........] - ETA: 19s - loss: 0.0461\n",
      "\n",
      "iteration=  254\n",
      "25600/36832 [===================>..........] - ETA: 19s - loss: 0.0461\n",
      "\n",
      "iteration=  255\n",
      "25856/36832 [====================>.........] - ETA: 19s - loss: 0.0460\n",
      "\n",
      "iteration=  256\n",
      "26112/36832 [====================>.........] - ETA: 18s - loss: 0.0461\n",
      "\n",
      "iteration=  257\n",
      "26368/36832 [====================>.........] - ETA: 18s - loss: 0.0461\n",
      "\n",
      "iteration=  258\n",
      "26624/36832 [====================>.........] - ETA: 17s - loss: 0.0461\n",
      "\n",
      "iteration=  259\n",
      "26880/36832 [====================>.........] - ETA: 17s - loss: 0.0460\n",
      "\n",
      "iteration=  260\n",
      "27136/36832 [=====================>........] - ETA: 16s - loss: 0.0460\n",
      "\n",
      "iteration=  261\n",
      "27392/36832 [=====================>........] - ETA: 16s - loss: 0.0462\n",
      "\n",
      "iteration=  262\n",
      "27648/36832 [=====================>........] - ETA: 15s - loss: 0.0461\n",
      "\n",
      "iteration=  263\n",
      "27904/36832 [=====================>........] - ETA: 15s - loss: 0.0461\n",
      "\n",
      "iteration=  264\n",
      "28160/36832 [=====================>........] - ETA: 15s - loss: 0.0460\n",
      "\n",
      "iteration=  265\n",
      "28416/36832 [======================>.......] - ETA: 14s - loss: 0.0461\n",
      "\n",
      "iteration=  266\n",
      "28672/36832 [======================>.......] - ETA: 14s - loss: 0.0461\n",
      "\n",
      "iteration=  267\n",
      "28928/36832 [======================>.......] - ETA: 13s - loss: 0.0462\n",
      "\n",
      "iteration=  268\n",
      "29184/36832 [======================>.......] - ETA: 13s - loss: 0.0461\n",
      "\n",
      "iteration=  269\n",
      "29440/36832 [======================>.......] - ETA: 12s - loss: 0.0463\n",
      "\n",
      "iteration=  270\n",
      "29696/36832 [=======================>......] - ETA: 12s - loss: 0.0463\n",
      "\n",
      "iteration=  271\n",
      "29952/36832 [=======================>......] - ETA: 11s - loss: 0.0463\n",
      "\n",
      "iteration=  272\n",
      "30208/36832 [=======================>......] - ETA: 11s - loss: 0.0463\n",
      "\n",
      "iteration=  273\n",
      "30464/36832 [=======================>......] - ETA: 11s - loss: 0.0461\n",
      "\n",
      "iteration=  274\n",
      "30720/36832 [========================>.....] - ETA: 10s - loss: 0.0460\n",
      "\n",
      "iteration=  275\n",
      "30976/36832 [========================>.....] - ETA: 10s - loss: 0.0459\n",
      "\n",
      "iteration=  276\n",
      "31232/36832 [========================>.....] - ETA: 9s - loss: 0.0459 \n",
      "\n",
      "iteration=  277\n",
      "31488/36832 [========================>.....] - ETA: 9s - loss: 0.0458\n",
      "\n",
      "iteration=  278\n",
      "31744/36832 [========================>.....] - ETA: 8s - loss: 0.0459\n",
      "\n",
      "iteration=  279\n",
      "32000/36832 [=========================>....] - ETA: 8s - loss: 0.0460\n",
      "\n",
      "iteration=  280\n",
      "32256/36832 [=========================>....] - ETA: 7s - loss: 0.0460\n",
      "\n",
      "iteration=  281\n",
      "32512/36832 [=========================>....] - ETA: 7s - loss: 0.0461\n",
      "\n",
      "iteration=  282\n",
      "32768/36832 [=========================>....] - ETA: 7s - loss: 0.0460\n",
      "\n",
      "iteration=  283\n",
      "33024/36832 [=========================>....] - ETA: 6s - loss: 0.0459\n",
      "\n",
      "iteration=  284\n",
      "33280/36832 [==========================>...] - ETA: 6s - loss: 0.0459\n",
      "\n",
      "iteration=  285\n",
      "33536/36832 [==========================>...] - ETA: 5s - loss: 0.0458\n",
      "\n",
      "iteration=  286\n",
      "33792/36832 [==========================>...] - ETA: 5s - loss: 0.0458\n",
      "\n",
      "iteration=  287\n",
      "34048/36832 [==========================>...] - ETA: 4s - loss: 0.0459\n",
      "\n",
      "iteration=  288\n",
      "34304/36832 [==========================>...] - ETA: 4s - loss: 0.0459\n",
      "\n",
      "iteration=  289\n",
      "34560/36832 [===========================>..] - ETA: 3s - loss: 0.0459\n",
      "\n",
      "iteration=  290\n",
      "34816/36832 [===========================>..] - ETA: 3s - loss: 0.0459\n",
      "\n",
      "iteration=  291\n",
      "35072/36832 [===========================>..] - ETA: 3s - loss: 0.0459\n",
      "\n",
      "iteration=  292\n",
      "35328/36832 [===========================>..] - ETA: 2s - loss: 0.0459\n",
      "\n",
      "iteration=  293\n",
      "35584/36832 [===========================>..] - ETA: 2s - loss: 0.0459\n",
      "\n",
      "iteration=  294\n",
      "35840/36832 [============================>.] - ETA: 1s - loss: 0.0459\n",
      "\n",
      "iteration=  295\n",
      "36096/36832 [============================>.] - ETA: 1s - loss: 0.0459\n",
      "\n",
      "iteration=  296\n",
      "36352/36832 [============================>.] - ETA: 0s - loss: 0.0459\n",
      "\n",
      "iteration=  297\n",
      "36608/36832 [============================>.] - ETA: 0s - loss: 0.0458\n",
      "\n",
      "iteration=  298\n",
      "36864/36832 [==============================] - 67s - loss: 0.0459 - val_loss: 0.0181\n",
      "Epoch 3/7\n",
      "\n",
      "\n",
      "iteration=  299\n",
      "  256/36832 [..............................] - ETA: 63s - loss: 0.0449\n",
      "\n",
      "iteration=  300\n",
      "  512/36832 [..............................] - ETA: 62s - loss: 0.0489\n",
      "\n",
      "iteration=  301\n",
      "  768/36832 [..............................] - ETA: 62s - loss: 0.0441\n",
      "\n",
      "iteration=  302\n",
      " 1024/36832 [..............................] - ETA: 62s - loss: 0.0411\n",
      "\n",
      "iteration=  303\n",
      " 1280/36832 [>.............................] - ETA: 61s - loss: 0.0418\n",
      "\n",
      "iteration=  304\n",
      " 1536/36832 [>.............................] - ETA: 61s - loss: 0.0419\n",
      "\n",
      "iteration=  305\n",
      " 1792/36832 [>.............................] - ETA: 60s - loss: 0.0437\n",
      "\n",
      "iteration=  306\n",
      " 2048/36832 [>.............................] - ETA: 60s - loss: 0.0439\n",
      "\n",
      "iteration=  307\n",
      " 2304/36832 [>.............................] - ETA: 59s - loss: 0.0448\n",
      "\n",
      "iteration=  308\n",
      " 2560/36832 [=>............................] - ETA: 59s - loss: 0.0455\n",
      "\n",
      "iteration=  309\n",
      " 2816/36832 [=>............................] - ETA: 59s - loss: 0.0454\n",
      "\n",
      "iteration=  310\n",
      " 3072/36832 [=>............................] - ETA: 58s - loss: 0.0465\n",
      "\n",
      "iteration=  311\n",
      " 3328/36832 [=>............................] - ETA: 58s - loss: 0.0468\n",
      "\n",
      "iteration=  312\n",
      " 3584/36832 [=>............................] - ETA: 57s - loss: 0.0468\n",
      "\n",
      "iteration=  313\n",
      " 3840/36832 [==>...........................] - ETA: 57s - loss: 0.0471\n",
      "\n",
      "iteration=  314\n",
      " 4096/36832 [==>...........................] - ETA: 56s - loss: 0.0470\n",
      "\n",
      "iteration=  315\n",
      " 4352/36832 [==>...........................] - ETA: 56s - loss: 0.0468\n",
      "\n",
      "iteration=  316\n",
      " 4608/36832 [==>...........................] - ETA: 55s - loss: 0.0468\n",
      "\n",
      "iteration=  317\n",
      " 4864/36832 [==>...........................] - ETA: 55s - loss: 0.0468\n",
      "\n",
      "iteration=  318\n",
      " 5120/36832 [===>..........................] - ETA: 55s - loss: 0.0462\n",
      "\n",
      "iteration=  319\n",
      " 5376/36832 [===>..........................] - ETA: 54s - loss: 0.0468\n",
      "\n",
      "iteration=  320\n",
      " 5632/36832 [===>..........................] - ETA: 54s - loss: 0.0468\n",
      "\n",
      "iteration=  321\n",
      " 5888/36832 [===>..........................] - ETA: 53s - loss: 0.0463\n",
      "\n",
      "iteration=  322\n",
      " 6144/36832 [====>.........................] - ETA: 53s - loss: 0.0464\n",
      "\n",
      "iteration=  323\n",
      " 6400/36832 [====>.........................] - ETA: 52s - loss: 0.0461\n",
      "\n",
      "iteration=  324\n",
      " 6656/36832 [====>.........................] - ETA: 52s - loss: 0.0455\n",
      "\n",
      "iteration=  325\n",
      " 6912/36832 [====>.........................] - ETA: 51s - loss: 0.0461\n",
      "\n",
      "iteration=  326\n",
      " 7168/36832 [====>.........................] - ETA: 51s - loss: 0.0461\n",
      "\n",
      "iteration=  327\n",
      " 7424/36832 [=====>........................] - ETA: 51s - loss: 0.0462\n",
      "\n",
      "iteration=  328\n",
      " 7680/36832 [=====>........................] - ETA: 50s - loss: 0.0464\n",
      "\n",
      "iteration=  329\n",
      " 7936/36832 [=====>........................] - ETA: 50s - loss: 0.0460\n",
      "\n",
      "iteration=  330\n",
      " 8192/36832 [=====>........................] - ETA: 49s - loss: 0.0463\n",
      "\n",
      "iteration=  331\n",
      " 8448/36832 [=====>........................] - ETA: 49s - loss: 0.0466\n",
      "\n",
      "iteration=  332\n",
      " 8704/36832 [======>.......................] - ETA: 48s - loss: 0.0464\n",
      "\n",
      "iteration=  333\n",
      " 8960/36832 [======>.......................] - ETA: 48s - loss: 0.0461\n",
      "\n",
      "iteration=  334\n",
      " 9216/36832 [======>.......................] - ETA: 47s - loss: 0.0460\n",
      "\n",
      "iteration=  335\n",
      " 9472/36832 [======>.......................] - ETA: 47s - loss: 0.0464\n",
      "\n",
      "iteration=  336\n",
      " 9728/36832 [======>.......................] - ETA: 47s - loss: 0.0463\n",
      "\n",
      "iteration=  337\n",
      " 9984/36832 [=======>......................] - ETA: 46s - loss: 0.0458\n",
      "\n",
      "iteration=  338\n",
      "10240/36832 [=======>......................] - ETA: 46s - loss: 0.0457\n",
      "\n",
      "iteration=  339\n",
      "10496/36832 [=======>......................] - ETA: 45s - loss: 0.0457\n",
      "\n",
      "iteration=  340\n",
      "10752/36832 [=======>......................] - ETA: 45s - loss: 0.0457\n",
      "\n",
      "iteration=  341\n",
      "11008/36832 [=======>......................] - ETA: 44s - loss: 0.0455\n",
      "\n",
      "iteration=  342\n",
      "11264/36832 [========>.....................] - ETA: 44s - loss: 0.0458\n",
      "\n",
      "iteration=  343\n",
      "11520/36832 [========>.....................] - ETA: 43s - loss: 0.0459\n",
      "\n",
      "iteration=  344\n",
      "11776/36832 [========>.....................] - ETA: 43s - loss: 0.0460\n",
      "\n",
      "iteration=  345\n",
      "12032/36832 [========>.....................] - ETA: 43s - loss: 0.0463\n",
      "\n",
      "iteration=  346\n",
      "12288/36832 [=========>....................] - ETA: 42s - loss: 0.0462\n",
      "\n",
      "iteration=  347\n",
      "12544/36832 [=========>....................] - ETA: 42s - loss: 0.0461\n",
      "\n",
      "iteration=  348\n",
      "12800/36832 [=========>....................] - ETA: 41s - loss: 0.0462\n",
      "\n",
      "iteration=  349\n",
      "13056/36832 [=========>....................] - ETA: 41s - loss: 0.0460\n",
      "\n",
      "iteration=  350\n",
      "13312/36832 [=========>....................] - ETA: 40s - loss: 0.0459\n",
      "\n",
      "iteration=  351\n",
      "13568/36832 [==========>...................] - ETA: 40s - loss: 0.0460\n",
      "\n",
      "iteration=  352\n",
      "13824/36832 [==========>...................] - ETA: 39s - loss: 0.0459\n",
      "\n",
      "iteration=  353\n",
      "14080/36832 [==========>...................] - ETA: 39s - loss: 0.0458\n",
      "\n",
      "iteration=  354\n",
      "14336/36832 [==========>...................] - ETA: 39s - loss: 0.0457\n",
      "\n",
      "iteration=  355\n",
      "14592/36832 [==========>...................] - ETA: 38s - loss: 0.0457\n",
      "\n",
      "iteration=  356\n",
      "14848/36832 [===========>..................] - ETA: 38s - loss: 0.0456\n",
      "\n",
      "iteration=  357\n",
      "15104/36832 [===========>..................] - ETA: 37s - loss: 0.0455\n",
      "\n",
      "iteration=  358\n",
      "15360/36832 [===========>..................] - ETA: 37s - loss: 0.0456\n",
      "\n",
      "iteration=  359\n",
      "15616/36832 [===========>..................] - ETA: 36s - loss: 0.0457\n",
      "\n",
      "iteration=  360\n",
      "15872/36832 [===========>..................] - ETA: 36s - loss: 0.0456\n",
      "\n",
      "iteration=  361\n",
      "16128/36832 [============>.................] - ETA: 35s - loss: 0.0455\n",
      "\n",
      "iteration=  362\n",
      "16384/36832 [============>.................] - ETA: 35s - loss: 0.0455\n",
      "\n",
      "iteration=  363\n",
      "16640/36832 [============>.................] - ETA: 35s - loss: 0.0453\n",
      "\n",
      "iteration=  364\n",
      "16896/36832 [============>.................] - ETA: 34s - loss: 0.0452\n",
      "\n",
      "iteration=  365\n",
      "17152/36832 [============>.................] - ETA: 34s - loss: 0.0451\n",
      "\n",
      "iteration=  366\n",
      "17408/36832 [=============>................] - ETA: 33s - loss: 0.0451\n",
      "\n",
      "iteration=  367\n",
      "17664/36832 [=============>................] - ETA: 33s - loss: 0.0449\n",
      "\n",
      "iteration=  368\n",
      "17920/36832 [=============>................] - ETA: 32s - loss: 0.0449\n",
      "\n",
      "iteration=  369\n",
      "18176/36832 [=============>................] - ETA: 32s - loss: 0.0451\n",
      "\n",
      "iteration=  370\n",
      "18432/36832 [==============>...............] - ETA: 31s - loss: 0.0452\n",
      "\n",
      "iteration=  371\n",
      "18688/36832 [==============>...............] - ETA: 31s - loss: 0.0451\n",
      "\n",
      "iteration=  372\n",
      "18944/36832 [==============>...............] - ETA: 31s - loss: 0.0449\n",
      "\n",
      "iteration=  373\n",
      "19200/36832 [==============>...............] - ETA: 30s - loss: 0.0448\n",
      "\n",
      "iteration=  374\n",
      "19456/36832 [==============>...............] - ETA: 30s - loss: 0.0448\n",
      "\n",
      "iteration=  375\n",
      "19712/36832 [===============>..............] - ETA: 29s - loss: 0.0449\n",
      "\n",
      "iteration=  376\n",
      "19968/36832 [===============>..............] - ETA: 29s - loss: 0.0447\n",
      "\n",
      "iteration=  377\n",
      "20224/36832 [===============>..............] - ETA: 28s - loss: 0.0446\n",
      "\n",
      "iteration=  378\n",
      "20480/36832 [===============>..............] - ETA: 28s - loss: 0.0449\n",
      "\n",
      "iteration=  379\n",
      "20736/36832 [===============>..............] - ETA: 27s - loss: 0.0447\n",
      "\n",
      "iteration=  380\n",
      "20992/36832 [================>.............] - ETA: 27s - loss: 0.0449\n",
      "\n",
      "iteration=  381\n",
      "21248/36832 [================>.............] - ETA: 27s - loss: 0.0448\n",
      "\n",
      "iteration=  382\n",
      "21504/36832 [================>.............] - ETA: 26s - loss: 0.0448\n",
      "\n",
      "iteration=  383\n",
      "21760/36832 [================>.............] - ETA: 26s - loss: 0.0450\n",
      "\n",
      "iteration=  384\n",
      "22016/36832 [================>.............] - ETA: 25s - loss: 0.0451\n",
      "\n",
      "iteration=  385\n",
      "22272/36832 [=================>............] - ETA: 25s - loss: 0.0451\n",
      "\n",
      "iteration=  386\n",
      "22528/36832 [=================>............] - ETA: 24s - loss: 0.0449\n",
      "\n",
      "iteration=  387\n",
      "22784/36832 [=================>............] - ETA: 24s - loss: 0.0450\n",
      "\n",
      "iteration=  388\n",
      "23040/36832 [=================>............] - ETA: 23s - loss: 0.0450\n",
      "\n",
      "iteration=  389\n",
      "23296/36832 [=================>............] - ETA: 23s - loss: 0.0450\n",
      "\n",
      "iteration=  390\n",
      "23552/36832 [==================>...........] - ETA: 23s - loss: 0.0449\n",
      "\n",
      "iteration=  391\n",
      "23808/36832 [==================>...........] - ETA: 22s - loss: 0.0450\n",
      "\n",
      "iteration=  392\n",
      "24064/36832 [==================>...........] - ETA: 22s - loss: 0.0449\n",
      "\n",
      "iteration=  393\n",
      "24320/36832 [==================>...........] - ETA: 21s - loss: 0.0449\n",
      "\n",
      "iteration=  394\n",
      "24576/36832 [===================>..........] - ETA: 21s - loss: 0.0448\n",
      "\n",
      "iteration=  395\n",
      "24832/36832 [===================>..........] - ETA: 20s - loss: 0.0449\n",
      "\n",
      "iteration=  396\n",
      "25088/36832 [===================>..........] - ETA: 20s - loss: 0.0450\n",
      "\n",
      "iteration=  397\n",
      "25344/36832 [===================>..........] - ETA: 19s - loss: 0.0448\n",
      "\n",
      "iteration=  398\n",
      "25600/36832 [===================>..........] - ETA: 19s - loss: 0.0449\n",
      "\n",
      "iteration=  399\n",
      "25856/36832 [====================>.........] - ETA: 19s - loss: 0.0448\n",
      "\n",
      "iteration=  400\n",
      "26112/36832 [====================>.........] - ETA: 18s - loss: 0.0447\n",
      "\n",
      "iteration=  401\n",
      "26368/36832 [====================>.........] - ETA: 18s - loss: 0.0448\n",
      "\n",
      "iteration=  402\n",
      "26624/36832 [====================>.........] - ETA: 17s - loss: 0.0448\n",
      "\n",
      "iteration=  403\n",
      "26880/36832 [====================>.........] - ETA: 17s - loss: 0.0448\n",
      "\n",
      "iteration=  404\n",
      "27136/36832 [=====================>........] - ETA: 16s - loss: 0.0447\n",
      "\n",
      "iteration=  405\n",
      "27392/36832 [=====================>........] - ETA: 16s - loss: 0.0447\n",
      "\n",
      "iteration=  406\n",
      "27648/36832 [=====================>........] - ETA: 15s - loss: 0.0449\n",
      "\n",
      "iteration=  407\n",
      "27904/36832 [=====================>........] - ETA: 15s - loss: 0.0448\n",
      "\n",
      "iteration=  408\n",
      "28160/36832 [=====================>........] - ETA: 15s - loss: 0.0448\n",
      "\n",
      "iteration=  409\n",
      "28416/36832 [======================>.......] - ETA: 14s - loss: 0.0447\n",
      "\n",
      "iteration=  410\n",
      "28672/36832 [======================>.......] - ETA: 14s - loss: 0.0447\n",
      "\n",
      "iteration=  411\n",
      "28928/36832 [======================>.......] - ETA: 13s - loss: 0.0447\n",
      "\n",
      "iteration=  412\n",
      "29184/36832 [======================>.......] - ETA: 13s - loss: 0.0448\n",
      "\n",
      "iteration=  413\n",
      "29440/36832 [======================>.......] - ETA: 12s - loss: 0.0447\n",
      "\n",
      "iteration=  414\n",
      "29696/36832 [=======================>......] - ETA: 12s - loss: 0.0448\n",
      "\n",
      "iteration=  415\n",
      "29952/36832 [=======================>......] - ETA: 11s - loss: 0.0447\n",
      "\n",
      "iteration=  416\n",
      "30208/36832 [=======================>......] - ETA: 11s - loss: 0.0446\n",
      "\n",
      "iteration=  417\n",
      "30464/36832 [=======================>......] - ETA: 11s - loss: 0.0445\n",
      "\n",
      "iteration=  418\n",
      "30720/36832 [========================>.....] - ETA: 10s - loss: 0.0444\n",
      "\n",
      "iteration=  419\n",
      "30976/36832 [========================>.....] - ETA: 10s - loss: 0.0443\n",
      "\n",
      "iteration=  420\n",
      "31232/36832 [========================>.....] - ETA: 9s - loss: 0.0443 \n",
      "\n",
      "iteration=  421\n",
      "31488/36832 [========================>.....] - ETA: 9s - loss: 0.0444\n",
      "\n",
      "iteration=  422\n",
      "31744/36832 [========================>.....] - ETA: 8s - loss: 0.0443\n",
      "\n",
      "iteration=  423\n",
      "32000/36832 [=========================>....] - ETA: 8s - loss: 0.0443\n",
      "\n",
      "iteration=  424\n",
      "32256/36832 [=========================>....] - ETA: 7s - loss: 0.0443\n",
      "\n",
      "iteration=  425\n",
      "32512/36832 [=========================>....] - ETA: 7s - loss: 0.0442\n",
      "\n",
      "iteration=  426\n",
      "32768/36832 [=========================>....] - ETA: 7s - loss: 0.0442\n",
      "\n",
      "iteration=  427\n",
      "33024/36832 [=========================>....] - ETA: 6s - loss: 0.0443\n",
      "\n",
      "iteration=  428\n",
      "33280/36832 [==========================>...] - ETA: 6s - loss: 0.0443\n",
      "\n",
      "iteration=  429\n",
      "33536/36832 [==========================>...] - ETA: 5s - loss: 0.0443\n",
      "\n",
      "iteration=  430\n",
      "33792/36832 [==========================>...] - ETA: 5s - loss: 0.0443\n",
      "\n",
      "iteration=  431\n",
      "34048/36832 [==========================>...] - ETA: 4s - loss: 0.0443\n",
      "\n",
      "iteration=  432\n",
      "34304/36832 [==========================>...] - ETA: 4s - loss: 0.0443\n",
      "\n",
      "iteration=  433\n",
      "34560/36832 [===========================>..] - ETA: 3s - loss: 0.0442\n",
      "\n",
      "iteration=  434\n",
      "34816/36832 [===========================>..] - ETA: 3s - loss: 0.0443\n",
      "\n",
      "iteration=  435\n",
      "35072/36832 [===========================>..] - ETA: 3s - loss: 0.0444\n",
      "\n",
      "iteration=  436\n",
      "35328/36832 [===========================>..] - ETA: 2s - loss: 0.0443\n",
      "\n",
      "iteration=  437\n",
      "35584/36832 [===========================>..] - ETA: 2s - loss: 0.0442\n",
      "\n",
      "iteration=  438\n",
      "35840/36832 [============================>.] - ETA: 1s - loss: 0.0442\n",
      "\n",
      "iteration=  439\n",
      "36096/36832 [============================>.] - ETA: 1s - loss: 0.0443\n",
      "\n",
      "iteration=  440\n",
      "36352/36832 [============================>.] - ETA: 0s - loss: 0.0443\n",
      "\n",
      "iteration=  441\n",
      "36608/36832 [============================>.] - ETA: 0s - loss: 0.0443\n",
      "\n",
      "iteration=  442\n",
      "36864/36832 [==============================] - 67s - loss: 0.0443 - val_loss: 0.0185\n",
      "Epoch 4/7\n",
      "\n",
      "\n",
      "iteration=  443\n",
      "  256/36832 [..............................] - ETA: 63s - loss: 0.0331\n",
      "\n",
      "iteration=  444\n",
      "  512/36832 [..............................] - ETA: 62s - loss: 0.0356\n",
      "\n",
      "iteration=  445\n",
      "  768/36832 [..............................] - ETA: 62s - loss: 0.0354\n",
      "\n",
      "iteration=  446\n",
      " 1024/36832 [..............................] - ETA: 62s - loss: 0.0376\n",
      "\n",
      "iteration=  447\n",
      " 1280/36832 [>.............................] - ETA: 61s - loss: 0.0359\n",
      "\n",
      "iteration=  448\n",
      " 1536/36832 [>.............................] - ETA: 61s - loss: 0.0373\n",
      "\n",
      "iteration=  449\n",
      " 1792/36832 [>.............................] - ETA: 60s - loss: 0.0393\n",
      "\n",
      "iteration=  450\n",
      " 2048/36832 [>.............................] - ETA: 60s - loss: 0.0388\n",
      "\n",
      "iteration=  451\n",
      " 2304/36832 [>.............................] - ETA: 59s - loss: 0.0380\n",
      "\n",
      "iteration=  452\n",
      " 2560/36832 [=>............................] - ETA: 59s - loss: 0.0389\n",
      "\n",
      "iteration=  453\n",
      " 2816/36832 [=>............................] - ETA: 59s - loss: 0.0379\n",
      "\n",
      "iteration=  454\n",
      " 3072/36832 [=>............................] - ETA: 58s - loss: 0.0390\n",
      "\n",
      "iteration=  455\n",
      " 3328/36832 [=>............................] - ETA: 58s - loss: 0.0402\n",
      "\n",
      "iteration=  456\n",
      " 3584/36832 [=>............................] - ETA: 57s - loss: 0.0401\n",
      "\n",
      "iteration=  457\n",
      " 3840/36832 [==>...........................] - ETA: 57s - loss: 0.0402\n",
      "\n",
      "iteration=  458\n",
      " 4096/36832 [==>...........................] - ETA: 56s - loss: 0.0407\n",
      "\n",
      "iteration=  459\n",
      " 4352/36832 [==>...........................] - ETA: 56s - loss: 0.0411\n",
      "\n",
      "iteration=  460\n",
      " 4608/36832 [==>...........................] - ETA: 55s - loss: 0.0412\n",
      "\n",
      "iteration=  461\n",
      " 4864/36832 [==>...........................] - ETA: 55s - loss: 0.0412\n",
      "\n",
      "iteration=  462\n",
      " 5120/36832 [===>..........................] - ETA: 55s - loss: 0.0406\n",
      "\n",
      "iteration=  463\n",
      " 5376/36832 [===>..........................] - ETA: 54s - loss: 0.0400\n",
      "\n",
      "iteration=  464\n",
      " 5632/36832 [===>..........................] - ETA: 54s - loss: 0.0405\n",
      "\n",
      "iteration=  465\n",
      " 5888/36832 [===>..........................] - ETA: 53s - loss: 0.0408\n",
      "\n",
      "iteration=  466\n",
      " 6144/36832 [====>.........................] - ETA: 53s - loss: 0.0405\n",
      "\n",
      "iteration=  467\n",
      " 6400/36832 [====>.........................] - ETA: 52s - loss: 0.0406\n",
      "\n",
      "iteration=  468\n",
      " 6656/36832 [====>.........................] - ETA: 52s - loss: 0.0411\n",
      "\n",
      "iteration=  469\n",
      " 6912/36832 [====>.........................] - ETA: 51s - loss: 0.0417\n",
      "\n",
      "iteration=  470\n",
      " 7168/36832 [====>.........................] - ETA: 51s - loss: 0.0419\n",
      "\n",
      "iteration=  471\n",
      " 7424/36832 [=====>........................] - ETA: 51s - loss: 0.0418\n",
      "\n",
      "iteration=  472\n",
      " 7680/36832 [=====>........................] - ETA: 50s - loss: 0.0419\n",
      "\n",
      "iteration=  473\n",
      " 7936/36832 [=====>........................] - ETA: 50s - loss: 0.0420\n",
      "\n",
      "iteration=  474\n",
      " 8192/36832 [=====>........................] - ETA: 49s - loss: 0.0422\n",
      "\n",
      "iteration=  475\n",
      " 8448/36832 [=====>........................] - ETA: 49s - loss: 0.0424\n",
      "\n",
      "iteration=  476\n",
      " 8704/36832 [======>.......................] - ETA: 48s - loss: 0.0425\n",
      "\n",
      "iteration=  477\n",
      " 8960/36832 [======>.......................] - ETA: 48s - loss: 0.0426\n",
      "\n",
      "iteration=  478\n",
      " 9216/36832 [======>.......................] - ETA: 47s - loss: 0.0426\n",
      "\n",
      "iteration=  479\n",
      " 9472/36832 [======>.......................] - ETA: 47s - loss: 0.0428\n",
      "\n",
      "iteration=  480\n",
      " 9728/36832 [======>.......................] - ETA: 47s - loss: 0.0425\n",
      "\n",
      "iteration=  481\n",
      " 9984/36832 [=======>......................] - ETA: 46s - loss: 0.0423\n",
      "\n",
      "iteration=  482\n",
      "10240/36832 [=======>......................] - ETA: 46s - loss: 0.0422\n",
      "\n",
      "iteration=  483\n",
      "10496/36832 [=======>......................] - ETA: 45s - loss: 0.0422\n",
      "\n",
      "iteration=  484\n",
      "10752/36832 [=======>......................] - ETA: 45s - loss: 0.0421\n",
      "\n",
      "iteration=  485\n",
      "11008/36832 [=======>......................] - ETA: 44s - loss: 0.0421\n",
      "\n",
      "iteration=  486\n",
      "11264/36832 [========>.....................] - ETA: 44s - loss: 0.0419\n",
      "\n",
      "iteration=  487\n",
      "11520/36832 [========>.....................] - ETA: 43s - loss: 0.0418\n",
      "\n",
      "iteration=  488\n",
      "11776/36832 [========>.....................] - ETA: 43s - loss: 0.0421\n",
      "\n",
      "iteration=  489\n",
      "12032/36832 [========>.....................] - ETA: 43s - loss: 0.0423\n",
      "\n",
      "iteration=  490\n",
      "12288/36832 [=========>....................] - ETA: 42s - loss: 0.0423\n",
      "\n",
      "iteration=  491\n",
      "12544/36832 [=========>....................] - ETA: 42s - loss: 0.0425\n",
      "\n",
      "iteration=  492\n",
      "12800/36832 [=========>....................] - ETA: 41s - loss: 0.0423\n",
      "\n",
      "iteration=  493\n",
      "13056/36832 [=========>....................] - ETA: 41s - loss: 0.0423\n",
      "\n",
      "iteration=  494\n",
      "13312/36832 [=========>....................] - ETA: 40s - loss: 0.0420\n",
      "\n",
      "iteration=  495\n",
      "13568/36832 [==========>...................] - ETA: 40s - loss: 0.0425\n",
      "\n",
      "iteration=  496\n",
      "13824/36832 [==========>...................] - ETA: 39s - loss: 0.0423\n",
      "\n",
      "iteration=  497\n",
      "14080/36832 [==========>...................] - ETA: 39s - loss: 0.0425\n",
      "\n",
      "iteration=  498\n",
      "14336/36832 [==========>...................] - ETA: 39s - loss: 0.0425\n",
      "\n",
      "iteration=  499\n",
      "14592/36832 [==========>...................] - ETA: 38s - loss: 0.0426\n",
      "\n",
      "iteration=  500\n",
      "14848/36832 [===========>..................] - ETA: 38s - loss: 0.0430\n",
      "\n",
      "iteration=  501\n",
      "15104/36832 [===========>..................] - ETA: 37s - loss: 0.0429\n",
      "\n",
      "iteration=  502\n",
      "15360/36832 [===========>..................] - ETA: 37s - loss: 0.0431\n",
      "\n",
      "iteration=  503\n",
      "15616/36832 [===========>..................] - ETA: 36s - loss: 0.0431\n",
      "\n",
      "iteration=  504\n",
      "15872/36832 [===========>..................] - ETA: 36s - loss: 0.0431\n",
      "\n",
      "iteration=  505\n",
      "16128/36832 [============>.................] - ETA: 35s - loss: 0.0431\n",
      "\n",
      "iteration=  506\n",
      "16384/36832 [============>.................] - ETA: 35s - loss: 0.0432\n",
      "\n",
      "iteration=  507\n",
      "16640/36832 [============>.................] - ETA: 35s - loss: 0.0431\n",
      "\n",
      "iteration=  508\n",
      "16896/36832 [============>.................] - ETA: 34s - loss: 0.0431\n",
      "\n",
      "iteration=  509\n",
      "17152/36832 [============>.................] - ETA: 34s - loss: 0.0429\n",
      "\n",
      "iteration=  510\n",
      "17408/36832 [=============>................] - ETA: 33s - loss: 0.0430\n",
      "\n",
      "iteration=  511\n",
      "17664/36832 [=============>................] - ETA: 33s - loss: 0.0429\n",
      "\n",
      "iteration=  512\n",
      "17920/36832 [=============>................] - ETA: 32s - loss: 0.0429\n",
      "\n",
      "iteration=  513\n",
      "18176/36832 [=============>................] - ETA: 32s - loss: 0.0429\n",
      "\n",
      "iteration=  514\n",
      "18432/36832 [==============>...............] - ETA: 31s - loss: 0.0430\n",
      "\n",
      "iteration=  515\n",
      "18688/36832 [==============>...............] - ETA: 31s - loss: 0.0430\n",
      "\n",
      "iteration=  516\n",
      "18944/36832 [==============>...............] - ETA: 31s - loss: 0.0432\n",
      "\n",
      "iteration=  517\n",
      "19200/36832 [==============>...............] - ETA: 30s - loss: 0.0432\n",
      "\n",
      "iteration=  518\n",
      "19456/36832 [==============>...............] - ETA: 30s - loss: 0.0433\n",
      "\n",
      "iteration=  519\n",
      "19712/36832 [===============>..............] - ETA: 29s - loss: 0.0433\n",
      "\n",
      "iteration=  520\n",
      "19968/36832 [===============>..............] - ETA: 29s - loss: 0.0433\n",
      "\n",
      "iteration=  521\n",
      "20224/36832 [===============>..............] - ETA: 28s - loss: 0.0433\n",
      "\n",
      "iteration=  522\n",
      "20480/36832 [===============>..............] - ETA: 28s - loss: 0.0436\n",
      "\n",
      "iteration=  523\n",
      "20736/36832 [===============>..............] - ETA: 27s - loss: 0.0437\n",
      "\n",
      "iteration=  524\n",
      "20992/36832 [================>.............] - ETA: 27s - loss: 0.0435\n",
      "\n",
      "iteration=  525\n",
      "21248/36832 [================>.............] - ETA: 27s - loss: 0.0435\n",
      "\n",
      "iteration=  526\n",
      "21504/36832 [================>.............] - ETA: 26s - loss: 0.0433\n",
      "\n",
      "iteration=  527\n",
      "21760/36832 [================>.............] - ETA: 26s - loss: 0.0433\n",
      "\n",
      "iteration=  528\n",
      "22016/36832 [================>.............] - ETA: 25s - loss: 0.0433\n",
      "\n",
      "iteration=  529\n",
      "22272/36832 [=================>............] - ETA: 25s - loss: 0.0433\n",
      "\n",
      "iteration=  530\n",
      "22528/36832 [=================>............] - ETA: 24s - loss: 0.0431\n",
      "\n",
      "iteration=  531\n",
      "22784/36832 [=================>............] - ETA: 24s - loss: 0.0430\n",
      "\n",
      "iteration=  532\n",
      "23040/36832 [=================>............] - ETA: 23s - loss: 0.0429\n",
      "\n",
      "iteration=  533\n",
      "23296/36832 [=================>............] - ETA: 23s - loss: 0.0431\n",
      "\n",
      "iteration=  534\n",
      "23552/36832 [==================>...........] - ETA: 23s - loss: 0.0432\n",
      "\n",
      "iteration=  535\n",
      "23808/36832 [==================>...........] - ETA: 22s - loss: 0.0434\n",
      "\n",
      "iteration=  536\n",
      "24064/36832 [==================>...........] - ETA: 22s - loss: 0.0433\n",
      "\n",
      "iteration=  537\n",
      "24320/36832 [==================>...........] - ETA: 21s - loss: 0.0434\n",
      "\n",
      "iteration=  538\n",
      "24576/36832 [===================>..........] - ETA: 21s - loss: 0.0432\n",
      "\n",
      "iteration=  539\n",
      "24832/36832 [===================>..........] - ETA: 20s - loss: 0.0432\n",
      "\n",
      "iteration=  540\n",
      "25088/36832 [===================>..........] - ETA: 20s - loss: 0.0431\n",
      "\n",
      "iteration=  541\n",
      "25344/36832 [===================>..........] - ETA: 19s - loss: 0.0429\n",
      "\n",
      "iteration=  542\n",
      "25600/36832 [===================>..........] - ETA: 19s - loss: 0.0428\n",
      "\n",
      "iteration=  543\n",
      "25856/36832 [====================>.........] - ETA: 19s - loss: 0.0429\n",
      "\n",
      "iteration=  544\n",
      "26112/36832 [====================>.........] - ETA: 18s - loss: 0.0428\n",
      "\n",
      "iteration=  545\n",
      "26368/36832 [====================>.........] - ETA: 18s - loss: 0.0428\n",
      "\n",
      "iteration=  546\n",
      "26624/36832 [====================>.........] - ETA: 17s - loss: 0.0428\n",
      "\n",
      "iteration=  547\n",
      "26880/36832 [====================>.........] - ETA: 17s - loss: 0.0428\n",
      "\n",
      "iteration=  548\n",
      "27136/36832 [=====================>........] - ETA: 16s - loss: 0.0428\n",
      "\n",
      "iteration=  549\n",
      "27392/36832 [=====================>........] - ETA: 16s - loss: 0.0427\n",
      "\n",
      "iteration=  550\n",
      "27648/36832 [=====================>........] - ETA: 15s - loss: 0.0427\n",
      "\n",
      "iteration=  551\n",
      "27904/36832 [=====================>........] - ETA: 15s - loss: 0.0427\n",
      "\n",
      "iteration=  552\n",
      "28160/36832 [=====================>........] - ETA: 15s - loss: 0.0427\n",
      "\n",
      "iteration=  553\n",
      "28416/36832 [======================>.......] - ETA: 14s - loss: 0.0427\n",
      "\n",
      "iteration=  554\n",
      "28672/36832 [======================>.......] - ETA: 14s - loss: 0.0428\n",
      "\n",
      "iteration=  555\n",
      "28928/36832 [======================>.......] - ETA: 13s - loss: 0.0427\n",
      "\n",
      "iteration=  556\n",
      "29184/36832 [======================>.......] - ETA: 13s - loss: 0.0428\n",
      "\n",
      "iteration=  557\n",
      "29440/36832 [======================>.......] - ETA: 12s - loss: 0.0428\n",
      "\n",
      "iteration=  558\n",
      "29696/36832 [=======================>......] - ETA: 12s - loss: 0.0429\n",
      "\n",
      "iteration=  559\n",
      "29952/36832 [=======================>......] - ETA: 11s - loss: 0.0429\n",
      "\n",
      "iteration=  560\n",
      "30208/36832 [=======================>......] - ETA: 11s - loss: 0.0429\n",
      "\n",
      "iteration=  561\n",
      "30464/36832 [=======================>......] - ETA: 11s - loss: 0.0429\n",
      "\n",
      "iteration=  562\n",
      "30720/36832 [========================>.....] - ETA: 10s - loss: 0.0429\n",
      "\n",
      "iteration=  563\n",
      "30976/36832 [========================>.....] - ETA: 10s - loss: 0.0429\n",
      "\n",
      "iteration=  564\n",
      "31232/36832 [========================>.....] - ETA: 9s - loss: 0.0429 \n",
      "\n",
      "iteration=  565\n",
      "31488/36832 [========================>.....] - ETA: 9s - loss: 0.0429\n",
      "\n",
      "iteration=  566\n",
      "31744/36832 [========================>.....] - ETA: 8s - loss: 0.0429\n",
      "\n",
      "iteration=  567\n",
      "32000/36832 [=========================>....] - ETA: 8s - loss: 0.0428\n",
      "\n",
      "iteration=  568\n",
      "32256/36832 [=========================>....] - ETA: 7s - loss: 0.0429\n",
      "\n",
      "iteration=  569\n",
      "32512/36832 [=========================>....] - ETA: 7s - loss: 0.0428\n",
      "\n",
      "iteration=  570\n",
      "32768/36832 [=========================>....] - ETA: 7s - loss: 0.0427\n",
      "\n",
      "iteration=  571\n",
      "33024/36832 [=========================>....] - ETA: 6s - loss: 0.0427\n",
      "\n",
      "iteration=  572\n",
      "33280/36832 [==========================>...] - ETA: 6s - loss: 0.0427\n",
      "\n",
      "iteration=  573\n",
      "33536/36832 [==========================>...] - ETA: 5s - loss: 0.0427\n",
      "\n",
      "iteration=  574\n",
      "33792/36832 [==========================>...] - ETA: 5s - loss: 0.0427\n",
      "\n",
      "iteration=  575\n",
      "34048/36832 [==========================>...] - ETA: 4s - loss: 0.0426\n",
      "\n",
      "iteration=  576\n",
      "34304/36832 [==========================>...] - ETA: 4s - loss: 0.0427\n",
      "\n",
      "iteration=  577\n",
      "34560/36832 [===========================>..] - ETA: 3s - loss: 0.0425\n",
      "\n",
      "iteration=  578\n",
      "34816/36832 [===========================>..] - ETA: 3s - loss: 0.0425\n",
      "\n",
      "iteration=  579\n",
      "35072/36832 [===========================>..] - ETA: 3s - loss: 0.0425\n",
      "\n",
      "iteration=  580\n",
      "35328/36832 [===========================>..] - ETA: 2s - loss: 0.0424\n",
      "\n",
      "iteration=  581\n",
      "35584/36832 [===========================>..] - ETA: 2s - loss: 0.0424\n",
      "\n",
      "iteration=  582\n",
      "35840/36832 [============================>.] - ETA: 1s - loss: 0.0424\n",
      "\n",
      "iteration=  583\n",
      "36096/36832 [============================>.] - ETA: 1s - loss: 0.0424\n",
      "\n",
      "iteration=  584\n",
      "36352/36832 [============================>.] - ETA: 0s - loss: 0.0424\n",
      "\n",
      "iteration=  585\n",
      "36608/36832 [============================>.] - ETA: 0s - loss: 0.0424\n",
      "\n",
      "iteration=  586\n",
      "36864/36832 [==============================] - 67s - loss: 0.0425 - val_loss: 0.0173\n",
      "Epoch 5/7\n",
      "\n",
      "\n",
      "iteration=  587\n",
      "  256/36832 [..............................] - ETA: 63s - loss: 0.0320\n",
      "\n",
      "iteration=  588\n",
      "  512/36832 [..............................] - ETA: 62s - loss: 0.0385\n",
      "\n",
      "iteration=  589\n",
      "  768/36832 [..............................] - ETA: 62s - loss: 0.0378\n",
      "\n",
      "iteration=  590\n",
      " 1024/36832 [..............................] - ETA: 62s - loss: 0.0426\n",
      "\n",
      "iteration=  591\n",
      " 1280/36832 [>.............................] - ETA: 61s - loss: 0.0414\n",
      "\n",
      "iteration=  592\n",
      " 1536/36832 [>.............................] - ETA: 61s - loss: 0.0421\n",
      "\n",
      "iteration=  593\n",
      " 1792/36832 [>.............................] - ETA: 60s - loss: 0.0424\n",
      "\n",
      "iteration=  594\n",
      " 2048/36832 [>.............................] - ETA: 60s - loss: 0.0411\n",
      "\n",
      "iteration=  595\n",
      " 2304/36832 [>.............................] - ETA: 59s - loss: 0.0407\n",
      "\n",
      "iteration=  596\n",
      " 2560/36832 [=>............................] - ETA: 59s - loss: 0.0416\n",
      "\n",
      "iteration=  597\n",
      " 2816/36832 [=>............................] - ETA: 59s - loss: 0.0412\n",
      "\n",
      "iteration=  598\n",
      " 3072/36832 [=>............................] - ETA: 58s - loss: 0.0417\n",
      "\n",
      "iteration=  599\n",
      " 3328/36832 [=>............................] - ETA: 58s - loss: 0.0429\n",
      "\n",
      "iteration=  600\n",
      " 3584/36832 [=>............................] - ETA: 57s - loss: 0.0430\n",
      "\n",
      "iteration=  601\n",
      " 3840/36832 [==>...........................] - ETA: 57s - loss: 0.0438\n",
      "\n",
      "iteration=  602\n",
      " 4096/36832 [==>...........................] - ETA: 56s - loss: 0.0437\n",
      "\n",
      "iteration=  603\n",
      " 4352/36832 [==>...........................] - ETA: 56s - loss: 0.0431\n",
      "\n",
      "iteration=  604\n",
      " 4608/36832 [==>...........................] - ETA: 55s - loss: 0.0431\n",
      "\n",
      "iteration=  605\n",
      " 4864/36832 [==>...........................] - ETA: 55s - loss: 0.0436\n",
      "\n",
      "iteration=  606\n",
      " 5120/36832 [===>..........................] - ETA: 55s - loss: 0.0433\n",
      "\n",
      "iteration=  607\n",
      " 5376/36832 [===>..........................] - ETA: 54s - loss: 0.0438\n",
      "\n",
      "iteration=  608\n",
      " 5632/36832 [===>..........................] - ETA: 54s - loss: 0.0444\n",
      "\n",
      "iteration=  609\n",
      " 5888/36832 [===>..........................] - ETA: 53s - loss: 0.0449\n",
      "\n",
      "iteration=  610\n",
      " 6144/36832 [====>.........................] - ETA: 53s - loss: 0.0451\n",
      "\n",
      "iteration=  611\n",
      " 6400/36832 [====>.........................] - ETA: 52s - loss: 0.0446\n",
      "\n",
      "iteration=  612\n",
      " 6656/36832 [====>.........................] - ETA: 52s - loss: 0.0444\n",
      "\n",
      "iteration=  613\n",
      " 6912/36832 [====>.........................] - ETA: 51s - loss: 0.0446\n",
      "\n",
      "iteration=  614\n",
      " 7168/36832 [====>.........................] - ETA: 51s - loss: 0.0446\n",
      "\n",
      "iteration=  615\n",
      " 7424/36832 [=====>........................] - ETA: 51s - loss: 0.0446\n",
      "\n",
      "iteration=  616\n",
      " 7680/36832 [=====>........................] - ETA: 50s - loss: 0.0452\n",
      "\n",
      "iteration=  617\n",
      " 7936/36832 [=====>........................] - ETA: 50s - loss: 0.0458\n",
      "\n",
      "iteration=  618\n",
      " 8192/36832 [=====>........................] - ETA: 49s - loss: 0.0455\n",
      "\n",
      "iteration=  619\n",
      " 8448/36832 [=====>........................] - ETA: 49s - loss: 0.0457\n",
      "\n",
      "iteration=  620\n",
      " 8704/36832 [======>.......................] - ETA: 48s - loss: 0.0456\n",
      "\n",
      "iteration=  621\n",
      " 8960/36832 [======>.......................] - ETA: 48s - loss: 0.0454\n",
      "\n",
      "iteration=  622\n",
      " 9216/36832 [======>.......................] - ETA: 47s - loss: 0.0456\n",
      "\n",
      "iteration=  623\n",
      " 9472/36832 [======>.......................] - ETA: 47s - loss: 0.0455\n",
      "\n",
      "iteration=  624\n",
      " 9728/36832 [======>.......................] - ETA: 47s - loss: 0.0454\n",
      "\n",
      "iteration=  625\n",
      " 9984/36832 [=======>......................] - ETA: 46s - loss: 0.0457\n",
      "\n",
      "iteration=  626\n",
      "10240/36832 [=======>......................] - ETA: 46s - loss: 0.0457\n",
      "\n",
      "iteration=  627\n",
      "10496/36832 [=======>......................] - ETA: 45s - loss: 0.0455\n",
      "\n",
      "iteration=  628\n",
      "10752/36832 [=======>......................] - ETA: 45s - loss: 0.0454\n",
      "\n",
      "iteration=  629\n",
      "11008/36832 [=======>......................] - ETA: 44s - loss: 0.0452\n",
      "\n",
      "iteration=  630\n",
      "11264/36832 [========>.....................] - ETA: 44s - loss: 0.0451\n",
      "\n",
      "iteration=  631\n",
      "11520/36832 [========>.....................] - ETA: 43s - loss: 0.0449\n",
      "\n",
      "iteration=  632\n",
      "11776/36832 [========>.....................] - ETA: 43s - loss: 0.0446\n",
      "\n",
      "iteration=  633\n",
      "12032/36832 [========>.....................] - ETA: 43s - loss: 0.0447\n",
      "\n",
      "iteration=  634\n",
      "12288/36832 [=========>....................] - ETA: 42s - loss: 0.0444\n",
      "\n",
      "iteration=  635\n",
      "12544/36832 [=========>....................] - ETA: 42s - loss: 0.0447\n",
      "\n",
      "iteration=  636\n",
      "12800/36832 [=========>....................] - ETA: 41s - loss: 0.0448\n",
      "\n",
      "iteration=  637\n",
      "13056/36832 [=========>....................] - ETA: 41s - loss: 0.0446\n",
      "\n",
      "iteration=  638\n",
      "13312/36832 [=========>....................] - ETA: 40s - loss: 0.0445\n",
      "\n",
      "iteration=  639\n",
      "13568/36832 [==========>...................] - ETA: 40s - loss: 0.0447\n",
      "\n",
      "iteration=  640\n",
      "13824/36832 [==========>...................] - ETA: 39s - loss: 0.0447\n",
      "\n",
      "iteration=  641\n",
      "14080/36832 [==========>...................] - ETA: 39s - loss: 0.0447\n",
      "\n",
      "iteration=  642\n",
      "14336/36832 [==========>...................] - ETA: 39s - loss: 0.0445\n",
      "\n",
      "iteration=  643\n",
      "14592/36832 [==========>...................] - ETA: 38s - loss: 0.0446\n",
      "\n",
      "iteration=  644\n",
      "14848/36832 [===========>..................] - ETA: 38s - loss: 0.0444\n",
      "\n",
      "iteration=  645\n",
      "15104/36832 [===========>..................] - ETA: 37s - loss: 0.0445\n",
      "\n",
      "iteration=  646\n",
      "15360/36832 [===========>..................] - ETA: 37s - loss: 0.0443\n",
      "\n",
      "iteration=  647\n",
      "15616/36832 [===========>..................] - ETA: 36s - loss: 0.0441\n",
      "\n",
      "iteration=  648\n",
      "15872/36832 [===========>..................] - ETA: 36s - loss: 0.0441\n",
      "\n",
      "iteration=  649\n",
      "16128/36832 [============>.................] - ETA: 35s - loss: 0.0441\n",
      "\n",
      "iteration=  650\n",
      "16384/36832 [============>.................] - ETA: 35s - loss: 0.0440\n",
      "\n",
      "iteration=  651\n",
      "16640/36832 [============>.................] - ETA: 35s - loss: 0.0442\n",
      "\n",
      "iteration=  652\n",
      "16896/36832 [============>.................] - ETA: 34s - loss: 0.0442\n",
      "\n",
      "iteration=  653\n",
      "17152/36832 [============>.................] - ETA: 34s - loss: 0.0445\n",
      "\n",
      "iteration=  654\n",
      "17408/36832 [=============>................] - ETA: 33s - loss: 0.0443\n",
      "\n",
      "iteration=  655\n",
      "17664/36832 [=============>................] - ETA: 33s - loss: 0.0445\n",
      "\n",
      "iteration=  656\n",
      "17920/36832 [=============>................] - ETA: 32s - loss: 0.0443\n",
      "\n",
      "iteration=  657\n",
      "18176/36832 [=============>................] - ETA: 32s - loss: 0.0444\n",
      "\n",
      "iteration=  658\n",
      "18432/36832 [==============>...............] - ETA: 31s - loss: 0.0443\n",
      "\n",
      "iteration=  659\n",
      "18688/36832 [==============>...............] - ETA: 31s - loss: 0.0443\n",
      "\n",
      "iteration=  660\n",
      "18944/36832 [==============>...............] - ETA: 31s - loss: 0.0444\n",
      "\n",
      "iteration=  661\n",
      "19200/36832 [==============>...............] - ETA: 30s - loss: 0.0443\n",
      "\n",
      "iteration=  662\n",
      "19456/36832 [==============>...............] - ETA: 30s - loss: 0.0443\n",
      "\n",
      "iteration=  663\n",
      "19712/36832 [===============>..............] - ETA: 29s - loss: 0.0443\n",
      "\n",
      "iteration=  664\n",
      "19968/36832 [===============>..............] - ETA: 29s - loss: 0.0443\n",
      "\n",
      "iteration=  665\n",
      "20224/36832 [===============>..............] - ETA: 28s - loss: 0.0442\n",
      "\n",
      "iteration=  666\n",
      "20480/36832 [===============>..............] - ETA: 28s - loss: 0.0441\n",
      "\n",
      "iteration=  667\n",
      "20736/36832 [===============>..............] - ETA: 27s - loss: 0.0441\n",
      "\n",
      "iteration=  668\n",
      "20992/36832 [================>.............] - ETA: 27s - loss: 0.0440\n",
      "\n",
      "iteration=  669\n",
      "21248/36832 [================>.............] - ETA: 27s - loss: 0.0441\n",
      "\n",
      "iteration=  670\n",
      "21504/36832 [================>.............] - ETA: 26s - loss: 0.0441\n",
      "\n",
      "iteration=  671\n",
      "21760/36832 [================>.............] - ETA: 26s - loss: 0.0441\n",
      "\n",
      "iteration=  672\n",
      "22016/36832 [================>.............] - ETA: 25s - loss: 0.0441\n",
      "\n",
      "iteration=  673\n",
      "22272/36832 [=================>............] - ETA: 25s - loss: 0.0440\n",
      "\n",
      "iteration=  674\n",
      "22528/36832 [=================>............] - ETA: 24s - loss: 0.0440\n",
      "\n",
      "iteration=  675\n",
      "22784/36832 [=================>............] - ETA: 24s - loss: 0.0441\n",
      "\n",
      "iteration=  676\n",
      "23040/36832 [=================>............] - ETA: 23s - loss: 0.0440\n",
      "\n",
      "iteration=  677\n",
      "23296/36832 [=================>............] - ETA: 23s - loss: 0.0440\n",
      "\n",
      "iteration=  678\n",
      "23552/36832 [==================>...........] - ETA: 23s - loss: 0.0441\n",
      "\n",
      "iteration=  679\n",
      "23808/36832 [==================>...........] - ETA: 22s - loss: 0.0442\n",
      "\n",
      "iteration=  680\n",
      "24064/36832 [==================>...........] - ETA: 22s - loss: 0.0442\n",
      "\n",
      "iteration=  681\n",
      "24320/36832 [==================>...........] - ETA: 21s - loss: 0.0441\n",
      "\n",
      "iteration=  682\n",
      "24576/36832 [===================>..........] - ETA: 21s - loss: 0.0440\n",
      "\n",
      "iteration=  683\n",
      "24832/36832 [===================>..........] - ETA: 20s - loss: 0.0442\n",
      "\n",
      "iteration=  684\n",
      "25088/36832 [===================>..........] - ETA: 20s - loss: 0.0442\n",
      "\n",
      "iteration=  685\n",
      "25344/36832 [===================>..........] - ETA: 19s - loss: 0.0441\n",
      "\n",
      "iteration=  686\n",
      "25600/36832 [===================>..........] - ETA: 19s - loss: 0.0441\n",
      "\n",
      "iteration=  687\n",
      "25856/36832 [====================>.........] - ETA: 19s - loss: 0.0441\n",
      "\n",
      "iteration=  688\n",
      "26112/36832 [====================>.........] - ETA: 18s - loss: 0.0441\n",
      "\n",
      "iteration=  689\n",
      "26368/36832 [====================>.........] - ETA: 18s - loss: 0.0441\n",
      "\n",
      "iteration=  690\n",
      "26624/36832 [====================>.........] - ETA: 17s - loss: 0.0440\n",
      "\n",
      "iteration=  691\n",
      "26880/36832 [====================>.........] - ETA: 17s - loss: 0.0440\n",
      "\n",
      "iteration=  692\n",
      "27136/36832 [=====================>........] - ETA: 16s - loss: 0.0439\n",
      "\n",
      "iteration=  693\n",
      "27392/36832 [=====================>........] - ETA: 16s - loss: 0.0440\n",
      "\n",
      "iteration=  694\n",
      "27648/36832 [=====================>........] - ETA: 15s - loss: 0.0440\n",
      "\n",
      "iteration=  695\n",
      "27904/36832 [=====================>........] - ETA: 15s - loss: 0.0440\n",
      "\n",
      "iteration=  696\n",
      "28160/36832 [=====================>........] - ETA: 15s - loss: 0.0440\n",
      "\n",
      "iteration=  697\n",
      "28416/36832 [======================>.......] - ETA: 14s - loss: 0.0440\n",
      "\n",
      "iteration=  698\n",
      "28672/36832 [======================>.......] - ETA: 14s - loss: 0.0441\n",
      "\n",
      "iteration=  699\n",
      "28928/36832 [======================>.......] - ETA: 13s - loss: 0.0440\n",
      "\n",
      "iteration=  700\n",
      "29184/36832 [======================>.......] - ETA: 13s - loss: 0.0440\n",
      "\n",
      "iteration=  701\n",
      "29440/36832 [======================>.......] - ETA: 12s - loss: 0.0439\n",
      "\n",
      "iteration=  702\n",
      "29696/36832 [=======================>......] - ETA: 12s - loss: 0.0441\n",
      "\n",
      "iteration=  703\n",
      "29952/36832 [=======================>......] - ETA: 11s - loss: 0.0440\n",
      "\n",
      "iteration=  704\n",
      "30208/36832 [=======================>......] - ETA: 11s - loss: 0.0439\n",
      "\n",
      "iteration=  705\n",
      "30464/36832 [=======================>......] - ETA: 11s - loss: 0.0439\n",
      "\n",
      "iteration=  706\n",
      "30720/36832 [========================>.....] - ETA: 10s - loss: 0.0440\n",
      "\n",
      "iteration=  707\n",
      "30976/36832 [========================>.....] - ETA: 10s - loss: 0.0440\n",
      "\n",
      "iteration=  708\n",
      "31232/36832 [========================>.....] - ETA: 9s - loss: 0.0440 \n",
      "\n",
      "iteration=  709\n",
      "31488/36832 [========================>.....] - ETA: 9s - loss: 0.0440\n",
      "\n",
      "iteration=  710\n",
      "31744/36832 [========================>.....] - ETA: 8s - loss: 0.0440\n",
      "\n",
      "iteration=  711\n",
      "32000/36832 [=========================>....] - ETA: 8s - loss: 0.0440\n",
      "\n",
      "iteration=  712\n",
      "32256/36832 [=========================>....] - ETA: 7s - loss: 0.0440\n",
      "\n",
      "iteration=  713\n",
      "32512/36832 [=========================>....] - ETA: 7s - loss: 0.0439\n",
      "\n",
      "iteration=  714\n",
      "32768/36832 [=========================>....] - ETA: 7s - loss: 0.0438\n",
      "\n",
      "iteration=  715\n",
      "33024/36832 [=========================>....] - ETA: 6s - loss: 0.0438\n",
      "\n",
      "iteration=  716\n",
      "33280/36832 [==========================>...] - ETA: 6s - loss: 0.0438\n",
      "\n",
      "iteration=  717\n",
      "33536/36832 [==========================>...] - ETA: 5s - loss: 0.0439\n",
      "\n",
      "iteration=  718\n",
      "33792/36832 [==========================>...] - ETA: 5s - loss: 0.0438\n",
      "\n",
      "iteration=  719\n",
      "34048/36832 [==========================>...] - ETA: 4s - loss: 0.0438\n",
      "\n",
      "iteration=  720\n",
      "34304/36832 [==========================>...] - ETA: 4s - loss: 0.0438\n",
      "\n",
      "iteration=  721\n",
      "34560/36832 [===========================>..] - ETA: 3s - loss: 0.0437\n",
      "\n",
      "iteration=  722\n",
      "34816/36832 [===========================>..] - ETA: 3s - loss: 0.0438\n",
      "\n",
      "iteration=  723\n",
      "35072/36832 [===========================>..] - ETA: 3s - loss: 0.0437\n",
      "\n",
      "iteration=  724\n",
      "35328/36832 [===========================>..] - ETA: 2s - loss: 0.0436\n",
      "\n",
      "iteration=  725\n",
      "35584/36832 [===========================>..] - ETA: 2s - loss: 0.0437\n",
      "\n",
      "iteration=  726\n",
      "35840/36832 [============================>.] - ETA: 1s - loss: 0.0437\n",
      "\n",
      "iteration=  727\n",
      "36096/36832 [============================>.] - ETA: 1s - loss: 0.0437\n",
      "\n",
      "iteration=  728\n",
      "36352/36832 [============================>.] - ETA: 0s - loss: 0.0437\n",
      "\n",
      "iteration=  729\n",
      "36608/36832 [============================>.] - ETA: 0s - loss: 0.0437\n",
      "\n",
      "iteration=  730\n",
      "36864/36832 [==============================] - 67s - loss: 0.0437 - val_loss: 0.0165\n",
      "Epoch 6/7\n",
      "\n",
      "\n",
      "iteration=  731\n",
      "  256/36832 [..............................] - ETA: 63s - loss: 0.0403\n",
      "\n",
      "iteration=  732\n",
      "  512/36832 [..............................] - ETA: 63s - loss: 0.0445\n",
      "\n",
      "iteration=  733\n",
      "  768/36832 [..............................] - ETA: 62s - loss: 0.0445\n",
      "\n",
      "iteration=  734\n",
      " 1024/36832 [..............................] - ETA: 62s - loss: 0.0446\n",
      "\n",
      "iteration=  735\n",
      " 1280/36832 [>.............................] - ETA: 61s - loss: 0.0437\n",
      "\n",
      "iteration=  736\n",
      " 1536/36832 [>.............................] - ETA: 61s - loss: 0.0432\n",
      "\n",
      "iteration=  737\n",
      " 1792/36832 [>.............................] - ETA: 60s - loss: 0.0415\n",
      "\n",
      "iteration=  738\n",
      " 2048/36832 [>.............................] - ETA: 60s - loss: 0.0417\n",
      "\n",
      "iteration=  739\n",
      " 2304/36832 [>.............................] - ETA: 59s - loss: 0.0436\n",
      "\n",
      "iteration=  740\n",
      " 2560/36832 [=>............................] - ETA: 59s - loss: 0.0449\n",
      "\n",
      "iteration=  741\n",
      " 2816/36832 [=>............................] - ETA: 59s - loss: 0.0456\n",
      "\n",
      "iteration=  742\n",
      " 3072/36832 [=>............................] - ETA: 58s - loss: 0.0445\n",
      "\n",
      "iteration=  743\n",
      " 3328/36832 [=>............................] - ETA: 58s - loss: 0.0437\n",
      "\n",
      "iteration=  744\n",
      " 3584/36832 [=>............................] - ETA: 57s - loss: 0.0428\n",
      "\n",
      "iteration=  745\n",
      " 3840/36832 [==>...........................] - ETA: 57s - loss: 0.0430\n",
      "\n",
      "iteration=  746\n",
      " 4096/36832 [==>...........................] - ETA: 56s - loss: 0.0429\n",
      "\n",
      "iteration=  747\n",
      " 4352/36832 [==>...........................] - ETA: 56s - loss: 0.0426\n",
      "\n",
      "iteration=  748\n",
      " 4608/36832 [==>...........................] - ETA: 55s - loss: 0.0435\n",
      "\n",
      "iteration=  749\n",
      " 4864/36832 [==>...........................] - ETA: 55s - loss: 0.0432\n",
      "\n",
      "iteration=  750\n",
      " 5120/36832 [===>..........................] - ETA: 55s - loss: 0.0432\n",
      "\n",
      "iteration=  751\n",
      " 5376/36832 [===>..........................] - ETA: 54s - loss: 0.0436\n",
      "\n",
      "iteration=  752\n",
      " 5632/36832 [===>..........................] - ETA: 54s - loss: 0.0435\n",
      "\n",
      "iteration=  753\n",
      " 5888/36832 [===>..........................] - ETA: 53s - loss: 0.0436\n",
      "\n",
      "iteration=  754\n",
      " 6144/36832 [====>.........................] - ETA: 53s - loss: 0.0430\n",
      "\n",
      "iteration=  755\n",
      " 6400/36832 [====>.........................] - ETA: 52s - loss: 0.0435\n",
      "\n",
      "iteration=  756\n",
      " 6656/36832 [====>.........................] - ETA: 52s - loss: 0.0432\n",
      "\n",
      "iteration=  757\n",
      " 6912/36832 [====>.........................] - ETA: 51s - loss: 0.0429\n",
      "\n",
      "iteration=  758\n",
      " 7168/36832 [====>.........................] - ETA: 51s - loss: 0.0429\n",
      "\n",
      "iteration=  759\n",
      " 7424/36832 [=====>........................] - ETA: 51s - loss: 0.0430\n",
      "\n",
      "iteration=  760\n",
      " 7680/36832 [=====>........................] - ETA: 50s - loss: 0.0430\n",
      "\n",
      "iteration=  761\n",
      " 7936/36832 [=====>........................] - ETA: 50s - loss: 0.0430\n",
      "\n",
      "iteration=  762\n",
      " 8192/36832 [=====>........................] - ETA: 49s - loss: 0.0429\n",
      "\n",
      "iteration=  763\n",
      " 8448/36832 [=====>........................] - ETA: 49s - loss: 0.0427\n",
      "\n",
      "iteration=  764\n",
      " 8704/36832 [======>.......................] - ETA: 48s - loss: 0.0424\n",
      "\n",
      "iteration=  765\n",
      " 8960/36832 [======>.......................] - ETA: 48s - loss: 0.0423\n",
      "\n",
      "iteration=  766\n",
      " 9216/36832 [======>.......................] - ETA: 47s - loss: 0.0421\n",
      "\n",
      "iteration=  767\n",
      " 9472/36832 [======>.......................] - ETA: 47s - loss: 0.0419\n",
      "\n",
      "iteration=  768\n",
      " 9728/36832 [======>.......................] - ETA: 47s - loss: 0.0419\n",
      "\n",
      "iteration=  769\n",
      " 9984/36832 [=======>......................] - ETA: 46s - loss: 0.0420\n",
      "\n",
      "iteration=  770\n",
      "10240/36832 [=======>......................] - ETA: 46s - loss: 0.0421\n",
      "\n",
      "iteration=  771\n",
      "10496/36832 [=======>......................] - ETA: 45s - loss: 0.0422\n",
      "\n",
      "iteration=  772\n",
      "10752/36832 [=======>......................] - ETA: 45s - loss: 0.0424\n",
      "\n",
      "iteration=  773\n",
      "11008/36832 [=======>......................] - ETA: 44s - loss: 0.0423\n",
      "\n",
      "iteration=  774\n",
      "11264/36832 [========>.....................] - ETA: 44s - loss: 0.0422\n",
      "\n",
      "iteration=  775\n",
      "11520/36832 [========>.....................] - ETA: 43s - loss: 0.0423\n",
      "\n",
      "iteration=  776\n",
      "11776/36832 [========>.....................] - ETA: 43s - loss: 0.0420\n",
      "\n",
      "iteration=  777\n",
      "12032/36832 [========>.....................] - ETA: 43s - loss: 0.0419\n",
      "\n",
      "iteration=  778\n",
      "12288/36832 [=========>....................] - ETA: 42s - loss: 0.0419\n",
      "\n",
      "iteration=  779\n",
      "12544/36832 [=========>....................] - ETA: 42s - loss: 0.0418\n",
      "\n",
      "iteration=  780\n",
      "12800/36832 [=========>....................] - ETA: 41s - loss: 0.0418\n",
      "\n",
      "iteration=  781\n",
      "13056/36832 [=========>....................] - ETA: 41s - loss: 0.0421\n",
      "\n",
      "iteration=  782\n",
      "13312/36832 [=========>....................] - ETA: 40s - loss: 0.0422\n",
      "\n",
      "iteration=  783\n",
      "13568/36832 [==========>...................] - ETA: 40s - loss: 0.0422\n",
      "\n",
      "iteration=  784\n",
      "13824/36832 [==========>...................] - ETA: 39s - loss: 0.0421\n",
      "\n",
      "iteration=  785\n",
      "14080/36832 [==========>...................] - ETA: 39s - loss: 0.0421\n",
      "\n",
      "iteration=  786\n",
      "14336/36832 [==========>...................] - ETA: 39s - loss: 0.0418\n",
      "\n",
      "iteration=  787\n",
      "14592/36832 [==========>...................] - ETA: 38s - loss: 0.0417\n",
      "\n",
      "iteration=  788\n",
      "14848/36832 [===========>..................] - ETA: 38s - loss: 0.0418\n",
      "\n",
      "iteration=  789\n",
      "15104/36832 [===========>..................] - ETA: 37s - loss: 0.0419\n",
      "\n",
      "iteration=  790\n",
      "15360/36832 [===========>..................] - ETA: 37s - loss: 0.0415\n",
      "\n",
      "iteration=  791\n",
      "15616/36832 [===========>..................] - ETA: 36s - loss: 0.0416\n",
      "\n",
      "iteration=  792\n",
      "15872/36832 [===========>..................] - ETA: 36s - loss: 0.0415\n",
      "\n",
      "iteration=  793\n",
      "16128/36832 [============>.................] - ETA: 35s - loss: 0.0414\n",
      "\n",
      "iteration=  794\n",
      "16384/36832 [============>.................] - ETA: 35s - loss: 0.0413\n",
      "\n",
      "iteration=  795\n",
      "16640/36832 [============>.................] - ETA: 35s - loss: 0.0411\n",
      "\n",
      "iteration=  796\n",
      "16896/36832 [============>.................] - ETA: 34s - loss: 0.0412\n",
      "\n",
      "iteration=  797\n",
      "17152/36832 [============>.................] - ETA: 34s - loss: 0.0409\n",
      "\n",
      "iteration=  798\n",
      "17408/36832 [=============>................] - ETA: 33s - loss: 0.0409\n",
      "\n",
      "iteration=  799\n",
      "17664/36832 [=============>................] - ETA: 33s - loss: 0.0409\n",
      "\n",
      "iteration=  800\n",
      "17920/36832 [=============>................] - ETA: 32s - loss: 0.0410\n",
      "\n",
      "iteration=  801\n",
      "18176/36832 [=============>................] - ETA: 32s - loss: 0.0408\n",
      "\n",
      "iteration=  802\n",
      "18432/36832 [==============>...............] - ETA: 31s - loss: 0.0407\n",
      "\n",
      "iteration=  803\n",
      "18688/36832 [==============>...............] - ETA: 31s - loss: 0.0408\n",
      "\n",
      "iteration=  804\n",
      "18944/36832 [==============>...............] - ETA: 31s - loss: 0.0409\n",
      "\n",
      "iteration=  805\n",
      "19200/36832 [==============>...............] - ETA: 30s - loss: 0.0409\n",
      "\n",
      "iteration=  806\n",
      "19456/36832 [==============>...............] - ETA: 30s - loss: 0.0409\n",
      "\n",
      "iteration=  807\n",
      "19712/36832 [===============>..............] - ETA: 29s - loss: 0.0410\n",
      "\n",
      "iteration=  808\n",
      "19968/36832 [===============>..............] - ETA: 29s - loss: 0.0409\n",
      "\n",
      "iteration=  809\n",
      "20224/36832 [===============>..............] - ETA: 28s - loss: 0.0408\n",
      "\n",
      "iteration=  810\n",
      "20480/36832 [===============>..............] - ETA: 28s - loss: 0.0407\n",
      "\n",
      "iteration=  811\n",
      "20736/36832 [===============>..............] - ETA: 27s - loss: 0.0408\n",
      "\n",
      "iteration=  812\n",
      "20992/36832 [================>.............] - ETA: 27s - loss: 0.0408\n",
      "\n",
      "iteration=  813\n",
      "21248/36832 [================>.............] - ETA: 27s - loss: 0.0409\n",
      "\n",
      "iteration=  814\n",
      "21504/36832 [================>.............] - ETA: 26s - loss: 0.0410\n",
      "\n",
      "iteration=  815\n",
      "21760/36832 [================>.............] - ETA: 26s - loss: 0.0412\n",
      "\n",
      "iteration=  816\n",
      "22016/36832 [================>.............] - ETA: 25s - loss: 0.0410\n",
      "\n",
      "iteration=  817\n",
      "22272/36832 [=================>............] - ETA: 25s - loss: 0.0411\n",
      "\n",
      "iteration=  818\n",
      "22528/36832 [=================>............] - ETA: 24s - loss: 0.0411\n",
      "\n",
      "iteration=  819\n",
      "22784/36832 [=================>............] - ETA: 24s - loss: 0.0412\n",
      "\n",
      "iteration=  820\n",
      "23040/36832 [=================>............] - ETA: 23s - loss: 0.0411\n",
      "\n",
      "iteration=  821\n",
      "23296/36832 [=================>............] - ETA: 23s - loss: 0.0413\n",
      "\n",
      "iteration=  822\n",
      "23552/36832 [==================>...........] - ETA: 23s - loss: 0.0413\n",
      "\n",
      "iteration=  823\n",
      "23808/36832 [==================>...........] - ETA: 22s - loss: 0.0413\n",
      "\n",
      "iteration=  824\n",
      "24064/36832 [==================>...........] - ETA: 22s - loss: 0.0414\n",
      "\n",
      "iteration=  825\n",
      "24320/36832 [==================>...........] - ETA: 21s - loss: 0.0413\n",
      "\n",
      "iteration=  826\n",
      "24576/36832 [===================>..........] - ETA: 21s - loss: 0.0412\n",
      "\n",
      "iteration=  827\n",
      "24832/36832 [===================>..........] - ETA: 20s - loss: 0.0413\n",
      "\n",
      "iteration=  828\n",
      "25088/36832 [===================>..........] - ETA: 20s - loss: 0.0413\n",
      "\n",
      "iteration=  829\n",
      "25344/36832 [===================>..........] - ETA: 19s - loss: 0.0415\n",
      "\n",
      "iteration=  830\n",
      "25600/36832 [===================>..........] - ETA: 19s - loss: 0.0417\n",
      "\n",
      "iteration=  831\n",
      "25856/36832 [====================>.........] - ETA: 19s - loss: 0.0416\n",
      "\n",
      "iteration=  832\n",
      "26112/36832 [====================>.........] - ETA: 18s - loss: 0.0416\n",
      "\n",
      "iteration=  833\n",
      "26368/36832 [====================>.........] - ETA: 18s - loss: 0.0416\n",
      "\n",
      "iteration=  834\n",
      "26624/36832 [====================>.........] - ETA: 17s - loss: 0.0416\n",
      "\n",
      "iteration=  835\n",
      "26880/36832 [====================>.........] - ETA: 17s - loss: 0.0416\n",
      "\n",
      "iteration=  836\n",
      "27136/36832 [=====================>........] - ETA: 16s - loss: 0.0418\n",
      "\n",
      "iteration=  837\n",
      "27392/36832 [=====================>........] - ETA: 16s - loss: 0.0418\n",
      "\n",
      "iteration=  838\n",
      "27648/36832 [=====================>........] - ETA: 15s - loss: 0.0418\n",
      "\n",
      "iteration=  839\n",
      "27904/36832 [=====================>........] - ETA: 15s - loss: 0.0419\n",
      "\n",
      "iteration=  840\n",
      "28160/36832 [=====================>........] - ETA: 15s - loss: 0.0418\n",
      "\n",
      "iteration=  841\n",
      "28416/36832 [======================>.......] - ETA: 14s - loss: 0.0419\n",
      "\n",
      "iteration=  842\n",
      "28672/36832 [======================>.......] - ETA: 14s - loss: 0.0418\n",
      "\n",
      "iteration=  843\n",
      "28928/36832 [======================>.......] - ETA: 13s - loss: 0.0419\n",
      "\n",
      "iteration=  844\n",
      "29184/36832 [======================>.......] - ETA: 13s - loss: 0.0419\n",
      "\n",
      "iteration=  845\n",
      "29440/36832 [======================>.......] - ETA: 12s - loss: 0.0420\n",
      "\n",
      "iteration=  846\n",
      "29696/36832 [=======================>......] - ETA: 12s - loss: 0.0419\n",
      "\n",
      "iteration=  847\n",
      "29952/36832 [=======================>......] - ETA: 11s - loss: 0.0418\n",
      "\n",
      "iteration=  848\n",
      "30208/36832 [=======================>......] - ETA: 11s - loss: 0.0419\n",
      "\n",
      "iteration=  849\n",
      "30464/36832 [=======================>......] - ETA: 11s - loss: 0.0418\n",
      "\n",
      "iteration=  850\n",
      "30720/36832 [========================>.....] - ETA: 10s - loss: 0.0418\n",
      "\n",
      "iteration=  851\n",
      "30976/36832 [========================>.....] - ETA: 10s - loss: 0.0418\n",
      "\n",
      "iteration=  852\n",
      "31232/36832 [========================>.....] - ETA: 9s - loss: 0.0419 \n",
      "\n",
      "iteration=  853\n",
      "31488/36832 [========================>.....] - ETA: 9s - loss: 0.0418\n",
      "\n",
      "iteration=  854\n",
      "31744/36832 [========================>.....] - ETA: 8s - loss: 0.0418\n",
      "\n",
      "iteration=  855\n",
      "32000/36832 [=========================>....] - ETA: 8s - loss: 0.0418\n",
      "\n",
      "iteration=  856\n",
      "32256/36832 [=========================>....] - ETA: 7s - loss: 0.0419\n",
      "\n",
      "iteration=  857\n",
      "32512/36832 [=========================>....] - ETA: 7s - loss: 0.0418\n",
      "\n",
      "iteration=  858\n",
      "32768/36832 [=========================>....] - ETA: 7s - loss: 0.0417\n",
      "\n",
      "iteration=  859\n",
      "33024/36832 [=========================>....] - ETA: 6s - loss: 0.0417\n",
      "\n",
      "iteration=  860\n",
      "33280/36832 [==========================>...] - ETA: 6s - loss: 0.0417\n",
      "\n",
      "iteration=  861\n",
      "33536/36832 [==========================>...] - ETA: 5s - loss: 0.0417\n",
      "\n",
      "iteration=  862\n",
      "33792/36832 [==========================>...] - ETA: 5s - loss: 0.0418\n",
      "\n",
      "iteration=  863\n",
      "34048/36832 [==========================>...] - ETA: 4s - loss: 0.0417\n",
      "\n",
      "iteration=  864\n",
      "34304/36832 [==========================>...] - ETA: 4s - loss: 0.0417\n",
      "\n",
      "iteration=  865\n",
      "34560/36832 [===========================>..] - ETA: 3s - loss: 0.0417\n",
      "\n",
      "iteration=  866\n",
      "34816/36832 [===========================>..] - ETA: 3s - loss: 0.0417\n",
      "\n",
      "iteration=  867\n",
      "35072/36832 [===========================>..] - ETA: 3s - loss: 0.0418\n",
      "\n",
      "iteration=  868\n",
      "35328/36832 [===========================>..] - ETA: 2s - loss: 0.0419\n",
      "\n",
      "iteration=  869\n",
      "35584/36832 [===========================>..] - ETA: 2s - loss: 0.0419\n",
      "\n",
      "iteration=  870\n",
      "35840/36832 [============================>.] - ETA: 1s - loss: 0.0418\n",
      "\n",
      "iteration=  871\n",
      "36096/36832 [============================>.] - ETA: 1s - loss: 0.0418\n",
      "\n",
      "iteration=  872\n",
      "36352/36832 [============================>.] - ETA: 0s - loss: 0.0418\n",
      "\n",
      "iteration=  873\n",
      "36608/36832 [============================>.] - ETA: 0s - loss: 0.0418\n",
      "\n",
      "iteration=  874\n",
      "36864/36832 [==============================] - 67s - loss: 0.0417 - val_loss: 0.0164\n",
      "Epoch 7/7\n",
      "\n",
      "\n",
      "iteration=  875\n",
      "  256/36832 [..............................] - ETA: 63s - loss: 0.0337\n",
      "\n",
      "iteration=  876\n",
      "  512/36832 [..............................] - ETA: 62s - loss: 0.0341\n",
      "\n",
      "iteration=  877\n",
      "  768/36832 [..............................] - ETA: 62s - loss: 0.0315\n",
      "\n",
      "iteration=  878\n",
      " 1024/36832 [..............................] - ETA: 62s - loss: 0.0380\n",
      "\n",
      "iteration=  879\n",
      " 1280/36832 [>.............................] - ETA: 61s - loss: 0.0376\n",
      "\n",
      "iteration=  880\n",
      " 1536/36832 [>.............................] - ETA: 61s - loss: 0.0373\n",
      "\n",
      "iteration=  881\n",
      " 1792/36832 [>.............................] - ETA: 60s - loss: 0.0384\n",
      "\n",
      "iteration=  882\n",
      " 2048/36832 [>.............................] - ETA: 60s - loss: 0.0404\n",
      "\n",
      "iteration=  883\n",
      " 2304/36832 [>.............................] - ETA: 59s - loss: 0.0420\n",
      "\n",
      "iteration=  884\n",
      " 2560/36832 [=>............................] - ETA: 59s - loss: 0.0414\n",
      "\n",
      "iteration=  885\n",
      " 2816/36832 [=>............................] - ETA: 59s - loss: 0.0415\n",
      "\n",
      "iteration=  886\n",
      " 3072/36832 [=>............................] - ETA: 58s - loss: 0.0426\n",
      "\n",
      "iteration=  887\n",
      " 3328/36832 [=>............................] - ETA: 58s - loss: 0.0429\n",
      "\n",
      "iteration=  888\n",
      " 3584/36832 [=>............................] - ETA: 57s - loss: 0.0421\n",
      "\n",
      "iteration=  889\n",
      " 3840/36832 [==>...........................] - ETA: 57s - loss: 0.0410\n",
      "\n",
      "iteration=  890\n",
      " 4096/36832 [==>...........................] - ETA: 56s - loss: 0.0413\n",
      "\n",
      "iteration=  891\n",
      " 4352/36832 [==>...........................] - ETA: 56s - loss: 0.0409\n",
      "\n",
      "iteration=  892\n",
      " 4608/36832 [==>...........................] - ETA: 55s - loss: 0.0406\n",
      "\n",
      "iteration=  893\n",
      " 4864/36832 [==>...........................] - ETA: 55s - loss: 0.0405\n",
      "\n",
      "iteration=  894\n",
      " 5120/36832 [===>..........................] - ETA: 55s - loss: 0.0405\n",
      "\n",
      "iteration=  895\n",
      " 5376/36832 [===>..........................] - ETA: 54s - loss: 0.0403\n",
      "\n",
      "iteration=  896\n",
      " 5632/36832 [===>..........................] - ETA: 54s - loss: 0.0406\n",
      "\n",
      "iteration=  897\n",
      " 5888/36832 [===>..........................] - ETA: 53s - loss: 0.0406\n",
      "\n",
      "iteration=  898\n",
      " 6144/36832 [====>.........................] - ETA: 53s - loss: 0.0405\n",
      "\n",
      "iteration=  899\n",
      " 6400/36832 [====>.........................] - ETA: 52s - loss: 0.0404\n",
      "\n",
      "iteration=  900\n",
      " 6656/36832 [====>.........................] - ETA: 52s - loss: 0.0405\n",
      "\n",
      "iteration=  901\n",
      " 6912/36832 [====>.........................] - ETA: 51s - loss: 0.0407\n",
      "\n",
      "iteration=  902\n",
      " 7168/36832 [====>.........................] - ETA: 51s - loss: 0.0405\n",
      "\n",
      "iteration=  903\n",
      " 7424/36832 [=====>........................] - ETA: 51s - loss: 0.0409\n",
      "\n",
      "iteration=  904\n",
      " 7680/36832 [=====>........................] - ETA: 50s - loss: 0.0409\n",
      "\n",
      "iteration=  905\n",
      " 7936/36832 [=====>........................] - ETA: 50s - loss: 0.0414\n",
      "\n",
      "iteration=  906\n",
      " 8192/36832 [=====>........................] - ETA: 49s - loss: 0.0411\n",
      "\n",
      "iteration=  907\n",
      " 8448/36832 [=====>........................] - ETA: 49s - loss: 0.0411\n",
      "\n",
      "iteration=  908\n",
      " 8704/36832 [======>.......................] - ETA: 48s - loss: 0.0408\n",
      "\n",
      "iteration=  909\n",
      " 8960/36832 [======>.......................] - ETA: 48s - loss: 0.0407\n",
      "\n",
      "iteration=  910\n",
      " 9216/36832 [======>.......................] - ETA: 47s - loss: 0.0406\n",
      "\n",
      "iteration=  911\n",
      " 9472/36832 [======>.......................] - ETA: 47s - loss: 0.0407\n",
      "\n",
      "iteration=  912\n",
      " 9728/36832 [======>.......................] - ETA: 47s - loss: 0.0409\n",
      "\n",
      "iteration=  913\n",
      " 9984/36832 [=======>......................] - ETA: 46s - loss: 0.0411\n",
      "\n",
      "iteration=  914\n",
      "10240/36832 [=======>......................] - ETA: 46s - loss: 0.0413\n",
      "\n",
      "iteration=  915\n",
      "10496/36832 [=======>......................] - ETA: 45s - loss: 0.0411\n",
      "\n",
      "iteration=  916\n",
      "10752/36832 [=======>......................] - ETA: 45s - loss: 0.0412\n",
      "\n",
      "iteration=  917\n",
      "11008/36832 [=======>......................] - ETA: 44s - loss: 0.0414\n",
      "\n",
      "iteration=  918\n",
      "11264/36832 [========>.....................] - ETA: 44s - loss: 0.0412\n",
      "\n",
      "iteration=  919\n",
      "11520/36832 [========>.....................] - ETA: 43s - loss: 0.0413\n",
      "\n",
      "iteration=  920\n",
      "11776/36832 [========>.....................] - ETA: 43s - loss: 0.0414\n",
      "\n",
      "iteration=  921\n",
      "12032/36832 [========>.....................] - ETA: 43s - loss: 0.0411\n",
      "\n",
      "iteration=  922\n",
      "12288/36832 [=========>....................] - ETA: 42s - loss: 0.0412\n",
      "\n",
      "iteration=  923\n",
      "12544/36832 [=========>....................] - ETA: 42s - loss: 0.0410\n",
      "\n",
      "iteration=  924\n",
      "12800/36832 [=========>....................] - ETA: 41s - loss: 0.0410\n",
      "\n",
      "iteration=  925\n",
      "13056/36832 [=========>....................] - ETA: 41s - loss: 0.0409\n",
      "\n",
      "iteration=  926\n",
      "13312/36832 [=========>....................] - ETA: 40s - loss: 0.0408\n",
      "\n",
      "iteration=  927\n",
      "13568/36832 [==========>...................] - ETA: 40s - loss: 0.0408\n",
      "\n",
      "iteration=  928\n",
      "13824/36832 [==========>...................] - ETA: 39s - loss: 0.0408\n",
      "\n",
      "iteration=  929\n",
      "14080/36832 [==========>...................] - ETA: 39s - loss: 0.0406\n",
      "\n",
      "iteration=  930\n",
      "14336/36832 [==========>...................] - ETA: 39s - loss: 0.0406\n",
      "\n",
      "iteration=  931\n",
      "14592/36832 [==========>...................] - ETA: 38s - loss: 0.0406\n",
      "\n",
      "iteration=  932\n",
      "14848/36832 [===========>..................] - ETA: 38s - loss: 0.0406\n",
      "\n",
      "iteration=  933\n",
      "15104/36832 [===========>..................] - ETA: 37s - loss: 0.0407\n",
      "\n",
      "iteration=  934\n",
      "15360/36832 [===========>..................] - ETA: 37s - loss: 0.0406\n",
      "\n",
      "iteration=  935\n",
      "15616/36832 [===========>..................] - ETA: 36s - loss: 0.0405\n",
      "\n",
      "iteration=  936\n",
      "15872/36832 [===========>..................] - ETA: 36s - loss: 0.0406\n",
      "\n",
      "iteration=  937\n",
      "16128/36832 [============>.................] - ETA: 35s - loss: 0.0403\n",
      "\n",
      "iteration=  938\n",
      "16384/36832 [============>.................] - ETA: 35s - loss: 0.0403\n",
      "\n",
      "iteration=  939\n",
      "16640/36832 [============>.................] - ETA: 35s - loss: 0.0403\n",
      "\n",
      "iteration=  940\n",
      "16896/36832 [============>.................] - ETA: 34s - loss: 0.0406\n",
      "\n",
      "iteration=  941\n",
      "17152/36832 [============>.................] - ETA: 34s - loss: 0.0405\n",
      "\n",
      "iteration=  942\n",
      "17408/36832 [=============>................] - ETA: 33s - loss: 0.0404\n",
      "\n",
      "iteration=  943\n",
      "17664/36832 [=============>................] - ETA: 33s - loss: 0.0405\n",
      "\n",
      "iteration=  944\n",
      "17920/36832 [=============>................] - ETA: 32s - loss: 0.0405\n",
      "\n",
      "iteration=  945\n",
      "18176/36832 [=============>................] - ETA: 32s - loss: 0.0403\n",
      "\n",
      "iteration=  946\n",
      "18432/36832 [==============>...............] - ETA: 31s - loss: 0.0404\n",
      "\n",
      "iteration=  947\n",
      "18688/36832 [==============>...............] - ETA: 31s - loss: 0.0403\n",
      "\n",
      "iteration=  948\n",
      "18944/36832 [==============>...............] - ETA: 31s - loss: 0.0403\n",
      "\n",
      "iteration=  949\n",
      "19200/36832 [==============>...............] - ETA: 30s - loss: 0.0403\n",
      "\n",
      "iteration=  950\n",
      "19456/36832 [==============>...............] - ETA: 30s - loss: 0.0402\n",
      "\n",
      "iteration=  951\n",
      "19712/36832 [===============>..............] - ETA: 29s - loss: 0.0404\n",
      "\n",
      "iteration=  952\n",
      "19968/36832 [===============>..............] - ETA: 29s - loss: 0.0403\n",
      "\n",
      "iteration=  953\n",
      "20224/36832 [===============>..............] - ETA: 28s - loss: 0.0403\n",
      "\n",
      "iteration=  954\n",
      "20480/36832 [===============>..............] - ETA: 28s - loss: 0.0405\n",
      "\n",
      "iteration=  955\n",
      "20736/36832 [===============>..............] - ETA: 27s - loss: 0.0404\n",
      "\n",
      "iteration=  956\n",
      "20992/36832 [================>.............] - ETA: 27s - loss: 0.0404\n",
      "\n",
      "iteration=  957\n",
      "21248/36832 [================>.............] - ETA: 27s - loss: 0.0404\n",
      "\n",
      "iteration=  958\n",
      "21504/36832 [================>.............] - ETA: 26s - loss: 0.0405\n",
      "\n",
      "iteration=  959\n",
      "21760/36832 [================>.............] - ETA: 26s - loss: 0.0405\n",
      "\n",
      "iteration=  960\n",
      "22016/36832 [================>.............] - ETA: 25s - loss: 0.0405\n",
      "\n",
      "iteration=  961\n",
      "22272/36832 [=================>............] - ETA: 25s - loss: 0.0405\n",
      "\n",
      "iteration=  962\n",
      "22528/36832 [=================>............] - ETA: 24s - loss: 0.0403\n",
      "\n",
      "iteration=  963\n",
      "22784/36832 [=================>............] - ETA: 24s - loss: 0.0405\n",
      "\n",
      "iteration=  964\n",
      "23040/36832 [=================>............] - ETA: 23s - loss: 0.0403\n",
      "\n",
      "iteration=  965\n",
      "23296/36832 [=================>............] - ETA: 23s - loss: 0.0402\n",
      "\n",
      "iteration=  966\n",
      "23552/36832 [==================>...........] - ETA: 23s - loss: 0.0402\n",
      "\n",
      "iteration=  967\n",
      "23808/36832 [==================>...........] - ETA: 22s - loss: 0.0402\n",
      "\n",
      "iteration=  968\n",
      "24064/36832 [==================>...........] - ETA: 22s - loss: 0.0402\n",
      "\n",
      "iteration=  969\n",
      "24320/36832 [==================>...........] - ETA: 21s - loss: 0.0404\n",
      "\n",
      "iteration=  970\n",
      "24576/36832 [===================>..........] - ETA: 21s - loss: 0.0405\n",
      "\n",
      "iteration=  971\n",
      "24832/36832 [===================>..........] - ETA: 20s - loss: 0.0405\n",
      "\n",
      "iteration=  972\n",
      "25088/36832 [===================>..........] - ETA: 20s - loss: 0.0405\n",
      "\n",
      "iteration=  973\n",
      "25344/36832 [===================>..........] - ETA: 19s - loss: 0.0406\n",
      "\n",
      "iteration=  974\n",
      "25600/36832 [===================>..........] - ETA: 19s - loss: 0.0405\n",
      "\n",
      "iteration=  975\n",
      "25856/36832 [====================>.........] - ETA: 19s - loss: 0.0405\n",
      "\n",
      "iteration=  976\n",
      "26112/36832 [====================>.........] - ETA: 18s - loss: 0.0407\n",
      "\n",
      "iteration=  977\n",
      "26368/36832 [====================>.........] - ETA: 18s - loss: 0.0407\n",
      "\n",
      "iteration=  978\n",
      "26624/36832 [====================>.........] - ETA: 17s - loss: 0.0407\n",
      "\n",
      "iteration=  979\n",
      "26880/36832 [====================>.........] - ETA: 17s - loss: 0.0407\n",
      "\n",
      "iteration=  980\n",
      "27136/36832 [=====================>........] - ETA: 16s - loss: 0.0407\n",
      "\n",
      "iteration=  981\n",
      "27392/36832 [=====================>........] - ETA: 16s - loss: 0.0408\n",
      "\n",
      "iteration=  982\n",
      "27648/36832 [=====================>........] - ETA: 15s - loss: 0.0408\n",
      "\n",
      "iteration=  983\n",
      "27904/36832 [=====================>........] - ETA: 15s - loss: 0.0407\n",
      "\n",
      "iteration=  984\n",
      "28160/36832 [=====================>........] - ETA: 15s - loss: 0.0407\n",
      "\n",
      "iteration=  985\n",
      "28416/36832 [======================>.......] - ETA: 14s - loss: 0.0406\n",
      "\n",
      "iteration=  986\n",
      "28672/36832 [======================>.......] - ETA: 14s - loss: 0.0405\n",
      "\n",
      "iteration=  987\n",
      "28928/36832 [======================>.......] - ETA: 13s - loss: 0.0405\n",
      "\n",
      "iteration=  988\n",
      "29184/36832 [======================>.......] - ETA: 13s - loss: 0.0405\n",
      "\n",
      "iteration=  989\n",
      "29440/36832 [======================>.......] - ETA: 12s - loss: 0.0405\n",
      "\n",
      "iteration=  990\n",
      "29696/36832 [=======================>......] - ETA: 12s - loss: 0.0404\n",
      "\n",
      "iteration=  991\n",
      "29952/36832 [=======================>......] - ETA: 11s - loss: 0.0405\n",
      "\n",
      "iteration=  992\n",
      "30208/36832 [=======================>......] - ETA: 11s - loss: 0.0406\n",
      "\n",
      "iteration=  993\n",
      "30464/36832 [=======================>......] - ETA: 11s - loss: 0.0407\n",
      "\n",
      "iteration=  994\n",
      "30720/36832 [========================>.....] - ETA: 10s - loss: 0.0409\n",
      "\n",
      "iteration=  995\n",
      "30976/36832 [========================>.....] - ETA: 10s - loss: 0.0411\n",
      "\n",
      "iteration=  996\n",
      "31232/36832 [========================>.....] - ETA: 9s - loss: 0.0410 \n",
      "\n",
      "iteration=  997\n",
      "31488/36832 [========================>.....] - ETA: 9s - loss: 0.0410\n",
      "\n",
      "iteration=  998\n",
      "31744/36832 [========================>.....] - ETA: 8s - loss: 0.0409\n",
      "\n",
      "iteration=  999\n",
      "32000/36832 [=========================>....] - ETA: 8s - loss: 0.0410\n",
      "\n",
      "iteration=  1000\n",
      "32256/36832 [=========================>....] - ETA: 7s - loss: 0.0409\n",
      "\n",
      "iteration=  1001\n",
      "32512/36832 [=========================>....] - ETA: 7s - loss: 0.0410\n",
      "\n",
      "iteration=  1002\n",
      "32768/36832 [=========================>....] - ETA: 7s - loss: 0.0410\n",
      "\n",
      "iteration=  1003\n",
      "33024/36832 [=========================>....] - ETA: 6s - loss: 0.0410\n",
      "\n",
      "iteration=  1004\n",
      "33280/36832 [==========================>...] - ETA: 6s - loss: 0.0412\n",
      "\n",
      "iteration=  1005\n",
      "33536/36832 [==========================>...] - ETA: 5s - loss: 0.0412\n",
      "\n",
      "iteration=  1006\n",
      "33792/36832 [==========================>...] - ETA: 5s - loss: 0.0412\n",
      "\n",
      "iteration=  1007\n",
      "34048/36832 [==========================>...] - ETA: 4s - loss: 0.0413\n",
      "\n",
      "iteration=  1008\n",
      "34304/36832 [==========================>...] - ETA: 4s - loss: 0.0412\n",
      "\n",
      "iteration=  1009\n",
      "34560/36832 [===========================>..] - ETA: 3s - loss: 0.0412\n",
      "\n",
      "iteration=  1010\n",
      "34816/36832 [===========================>..] - ETA: 3s - loss: 0.0412\n",
      "\n",
      "iteration=  1011\n",
      "35072/36832 [===========================>..] - ETA: 3s - loss: 0.0412\n",
      "\n",
      "iteration=  1012\n",
      "35328/36832 [===========================>..] - ETA: 2s - loss: 0.0411\n",
      "\n",
      "iteration=  1013\n",
      "35584/36832 [===========================>..] - ETA: 2s - loss: 0.0411\n",
      "\n",
      "iteration=  1014\n",
      "35840/36832 [============================>.] - ETA: 1s - loss: 0.0410\n",
      "\n",
      "iteration=  1015\n",
      "36096/36832 [============================>.] - ETA: 1s - loss: 0.0411\n",
      "\n",
      "iteration=  1016\n",
      "36352/36832 [============================>.] - ETA: 0s - loss: 0.0412\n",
      "\n",
      "iteration=  1017\n",
      "36608/36832 [============================>.] - ETA: 0s - loss: 0.0412\n",
      "\n",
      "iteration=  1018\n",
      "36864/36832 [==============================] - 67s - loss: 0.0413 - val_loss: 0.0165\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "nb_epoch_total = 7\n",
    "batch_size = 256\n",
    "\n",
    "training_generator = myTrainGenerator(batch_size)\n",
    "validation_generator = myValidationGenerator(X_valid, y_valid, batch_size)\n",
    "\n",
    "history = model.fit_generator(training_generator,\n",
    "                              samples_per_epoch=len(X_train),\n",
    "                              nb_epoch=nb_epoch_total,\n",
    "                              validation_data=validation_generator,\n",
    "                              nb_val_samples=len(X_valid))\n",
    "\n",
    "print('Training completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Save the model and weights\n",
    "\n",
    "Model architecture to be saved in model.json\n",
    "\n",
    "Model weights to be saved in model.h5\n",
    "\n",
    "OR\n",
    "\n",
    "Model architecture and weights compiled and saved in model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "#model_json = model.to_json()\n",
    "#with open(\"model.json\", \"w\") as json_file:\n",
    "    #json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "#model.save_weights(\"model.h5\")\n",
    "\n",
    "# serialize compiled model arch and weights in HDF5\n",
    "model.save('model.h5') \n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
